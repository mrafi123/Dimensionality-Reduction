{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce 920M (0000:08:00.0)\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda,floatX=float32\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, UpSampling3D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Deconvolution2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "img_rows = 32\n",
    "img_cols = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<GpuArrayType<None>(float32, (False,))>), HostFromGpu(gpuarray)(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.943745 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    }
   ],
   "source": [
    "#test for gpu\n",
    "from theano import function, config, shared, tensor\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], tensor.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, tensor.Elemwise) and\n",
    "              ('Gpu' not in type(x.op).__name__)\n",
    "              for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    # bulid the generator model, it is a model made up of UpSample and Convolution\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=2048, init='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Dense(2048))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Reshape((2, 2, 512), input_shape=(2048,))) commented by me next line added by me\n",
    "    model.add(Reshape((512, 2, 2), input_shape=(2048,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(256, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(3, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    print ('Generator model...')\n",
    "    print (model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def Discriminator():\n",
    "    model = Sequential()\n",
    "    #model.add(Convolution2D(64, 5, 5, border_mode='same',subsample=(2, 2), input_shape=(32, 32, 3))) commented by me next line added by me\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same',subsample=(2, 2), input_shape=(3, 32, 32)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(Convolution2D(256, 5, 5, border_mode='same', subsample=(2,2)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(Convolution2D(512, 5, 5, border_mode='same', subsample=(4,4)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    print ('Discriminator model...')\n",
    "\n",
    "    print (model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "# Note that you will have to change the output_shape depending on the backend used.\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    #print ('num ',num)\n",
    "    width = int(math.sqrt(num))\n",
    "    #print ('width ',width)\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    #print ('height ',height)\n",
    "    #print ('generated images shape before reshape ',generated_images.shape)\n",
    "    ## added the below line to overcome the poor quality of image generated issue with RGB channel \n",
    "    generated_images = generated_images.reshape(generated_images.shape[0], 3, 32, 32).transpose(0,2,3,1)\n",
    "\n",
    "    generated_images = generated_images.reshape((generated_images.shape[0], 32, 32, 3) )\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], 3),dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 0] = \\\n",
    "            img[:, :, 0]\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 1] = \\\n",
    "            img[:, :, 1]\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 2] = \\\n",
    "            img[:, :, 2]\n",
    "    return image\n",
    "\n",
    "\n",
    "def train(BATCH_SIZE, epoch_num):\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    #print X_train.dtype\n",
    "    #X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    #print X_train.dtype\n",
    "    print ('downloaded X_train shape ',X_train.shape)\n",
    "    print ('downloaded X_test shape ', X_test.shape)\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    #X_train /= 255\n",
    "    X_train = (X_train - 127.5)/127.5\n",
    "    X_test /= 255\n",
    "    X_train = X_train.reshape((X_train.shape[0], ) + X_train.shape[1:])\n",
    "    #X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    print ('X_train shape ',X_train.shape)\n",
    "    print ('X_test shape ', X_test.shape)\n",
    "    discriminator = Discriminator()\n",
    "    print ('Discriminator initialized...')\n",
    "    generator = Generator()\n",
    "    print ('Generator initialized...')\n",
    "\n",
    "    discriminator_on_generator = generator_containing_discriminator(generator, discriminator)\n",
    "    print ('generator_containing_discriminator initialized...')\n",
    "    \n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.5, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.5, nesterov=True)\n",
    "    d_optim = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    print ('noise shape ',noise.shape)\n",
    "    #for epoch in range(100):\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "    \n",
    "        batches_num = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        # load weights on first try (i.e. if process failed previously and we are attempting to recapture lost data)\n",
    "        \n",
    "        if epoch == 0:\n",
    "            if os.path.exists('generator_cifar') and os.path.exists('discriminator_cifar'):\n",
    "                print (\"Loading saves weights..\")\n",
    "                generator.load_weights('generator_cifar')\n",
    "                discriminator.load_weights('discriminator_cifar')\n",
    "                print (\"Finished loading\")\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        for index in range(batches_num):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "                #print 'noise', noise.dtype\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(noise, [0.9] * BATCH_SIZE)\n",
    "            \n",
    "            #filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "            #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "            #callbacks_list = [checkpoint]\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            #print(\"epoch %d/%d batch %d/%d g_loss : %f\" % (epoch+1, epoch_num,index, batches_num, g_loss))\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            \n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            \n",
    "            if index % 64 == 0:\n",
    "                gen_image = combine_images(generated_images)\n",
    "                gen_image = gen_image.reshape(384, 352, 3)\n",
    "                gen_image = gen_image*127.5+127.5\n",
    "                Image.fromarray(gen_image.astype(np.uint8)).save('images/gen_image'+\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "\n",
    "                org_image = combine_images(image_batch)\n",
    "                org_image = org_image.reshape(384, 352, 3)\n",
    "                org_image = org_image*127.5+127.5\n",
    "                Image.fromarray(org_image.astype(np.uint8)).save('images/org_image'+\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "\n",
    "                #print image_batch.shape, generated_images.shape\n",
    "\n",
    "            X = np.concatenate((image_batch, generated_images))           \n",
    "            y = [0.9] * BATCH_SIZE + [0.0] * BATCH_SIZE\n",
    "            #y = np.array(y)\n",
    "            #print 'y ', y.shape\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            #print(\"epoch %d/%d batch %d/%d d_loss : %f\" % (epoch+1, epoch_num, index, batches_num, d_loss))\n",
    "            #for i in range(BATCH_SIZE):\n",
    "            #    noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            #discriminator.trainable = False\n",
    "            '''g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, np.array([1.0] * BATCH_SIZE))\n",
    "            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            '''\n",
    "            if index % 50 == 0:\n",
    "                generator.save_weights('generator_cifar', True)\n",
    "                discriminator.save_weights('discriminator_cifar', True)\n",
    "\n",
    "'''\n",
    "def generate(BATCH_SIZE, nice=False):\n",
    "    generator = Generator()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"Adam\")\n",
    "    generator.load_weights('generator_cifar')\n",
    "    if nice:\n",
    "        discriminator = Discriminator()\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer=\"Adam\")\n",
    "        discriminator.load_weights('discriminator_cifar')\n",
    "        noise = np.zeros((BATCH_SIZE*20, 100))\n",
    "        for i in range(BATCH_SIZE*20):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        print generated_images.shape\n",
    "        d_pret = discriminator.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE, ) +\n",
    "                           (generated_images.shape[1:3]) + (1,), dtype=np.float32)\n",
    "        for i in range(int(BATCH_SIZE)):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.zeros((BATCH_SIZE, 100))\n",
    "        for i in range(BATCH_SIZE):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    #image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")\n",
    "'''\n",
    "\n",
    "def generate(BATCH_SIZE):\n",
    "    generator = Generator()\n",
    "    d_optim = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    g_optim = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    generator.load_weights('generator_cifar')\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    for i in range(BATCH_SIZE):\n",
    "    \tnoise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    print ('after generator predict generated images shape',generated_images.shape)\n",
    "    image = combine_images(generated_images)\n",
    "\n",
    "    image = image.reshape(384, 352, 3)\n",
    "\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")\n",
    "\n",
    "    #clr_img = Image.fromarray(image,'RGB')   \n",
    "    #clr_img.save(\"generated_image_clr.png\")\n",
    "    \n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
    "    parser.add_argument(\"--epoch_num\",type=int,default=100)\n",
    "    parser.set_defaults(nice=False)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not os.path.exists('images'):\n",
    "        os.mkdir('images')\n",
    "    args = get_args()\n",
    "    if args.mode == \"train\":\n",
    "        print ('totol epochs of the train:'+str(args.epoch_num))\n",
    "        train(BATCH_SIZE=args.batch_size, epoch_num=args.epoch_num)\n",
    "    elif args.mode == \"generate\":\n",
    "        generate(BATCH_SIZE=args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.mkdir('images')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded X_train shape  (50000, 3, 32, 32)\n",
      "downloaded X_test shape  (10000, 3, 32, 32)\n",
      "X_train shape  (50000, 3, 32, 32)\n",
      "X_test shape  (10000, 3, 32, 32)\n",
      "Discriminator model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 16, 16)    4864        convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)          (None, 64, 16, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 128, 8, 8)     204928      leakyrelu_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_2 (LeakyReLU)          (None, 128, 8, 8)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 256, 4, 4)     819456      leakyrelu_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)          (None, 256, 4, 4)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 512, 1, 1)     3277312     leakyrelu_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 512, 1, 1)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           leakyrelu_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             513         flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4,307,073\n",
      "Trainable params: 4,307,073\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Discriminator initialized...\n",
      "Generator model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_2 (Dense)                  (None, 2048)          206848      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 2048)          8192        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2048)          0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 512, 2, 2)     0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_1 (UpSampling2D)    (None, 512, 4, 4)     0           reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 4, 4)     3277056     upsampling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 256, 4, 4)     16          convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 256, 4, 4)     0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_2 (UpSampling2D)    (None, 256, 8, 8)     0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 128, 8, 8)     819328      upsampling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 128, 8, 8)     32          convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 128, 8, 8)     0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_3 (UpSampling2D)    (None, 128, 16, 16)   0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 64, 16, 16)    204864      upsampling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 64, 16, 16)    64          convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 64, 16, 16)    0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_4 (UpSampling2D)    (None, 64, 32, 32)    0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 3, 32, 32)     4803        upsampling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 3, 32, 32)     0           convolution2d_8[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 4,521,203\n",
      "Trainable params: 4,517,051\n",
      "Non-trainable params: 4,152\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Generator initialized...\n",
      "generator_containing_discriminator initialized...\n",
      "noise shape  (128, 100)\n",
      "Epoch is 0\n",
      "Number of batches 390\n",
      "Loading saves weights..\n",
      "Finished loading\n",
      "Epoch is 1\n",
      "Number of batches 390\n"
     ]
    }
   ],
   "source": [
    "#Training the model - python cifar_gan.py --mode train --batch_size 128 --epoch_num 200\n",
    "train(BATCH_SIZE=128, epoch_num=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_5 (Dense)                  (None, 2048)          206848      dense_input_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 2048)          8192        dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 2048)          0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 512, 2, 2)     0           activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_9 (UpSampling2D)    (None, 512, 4, 4)     0           reshape_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 256, 4, 4)     3277056     upsampling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 256, 4, 4)     16          convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 256, 4, 4)     0           batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_10 (UpSampling2D)   (None, 256, 8, 8)     0           activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 128, 8, 8)     819328      upsampling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 128, 8, 8)     32          convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 128, 8, 8)     0           batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_11 (UpSampling2D)   (None, 128, 16, 16)   0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 64, 16, 16)    204864      upsampling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 64, 16, 16)    64          convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 64, 16, 16)    0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_12 (UpSampling2D)   (None, 64, 32, 32)    0           activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 3, 32, 32)     4803        upsampling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 3, 32, 32)     0           convolution2d_28[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 4,521,203\n",
      "Trainable params: 4,517,051\n",
      "Non-trainable params: 4,152\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "AbstractConv shape mismatch: shape of filters does not match given kshp.\nApply node that caused the error: Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}(convolution2d_25_W, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0)\nToposort index: 72\nInputs types: [GpuArrayType<None>(float32, (False, False, False, False)), TensorType(bool, scalar), TensorType(bool, scalar), TensorType(bool, scalar), TensorType(bool, scalar)]\nInputs shapes: [(5, 5, 512, 256), (), (), (), ()]\nInputs strides: [(2621440, 524288, 1024, 4), (), (), (), ()]\nInputs values: ['not shown', array(False, dtype=bool), array(False, dtype=bool), array(False, dtype=bool), array(False, dtype=bool)]\nOutputs clients: [[Shape(Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}.0), Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}(Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: AbstractConv shape mismatch: shape of filters does not match given kshp.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6d33fa353f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-ce202bb17cfe>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(BATCH_SIZE)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mnoise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m     \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after generator predict generated images shape'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[1;32m-> 1272\u001b[1;33m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: AbstractConv shape mismatch: shape of filters does not match given kshp.\nApply node that caused the error: Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}(convolution2d_25_W, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0)\nToposort index: 72\nInputs types: [GpuArrayType<None>(float32, (False, False, False, False)), TensorType(bool, scalar), TensorType(bool, scalar), TensorType(bool, scalar), TensorType(bool, scalar)]\nInputs shapes: [(5, 5, 512, 256), (), (), (), ()]\nInputs strides: [(2621440, 524288, 1024, 4), (), (), (), ()]\nInputs values: ['not shown', array(False, dtype=bool), array(False, dtype=bool), array(False, dtype=bool), array(False, dtype=bool)]\nOutputs clients: [[Shape(Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}.0), Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}(Assert{msg='AbstractConv shape mismatch: shape of filters does not match given kshp.'}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0, Elemwise{eq,no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "generate(BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Completed Traiing and Generation\n",
    "### Begin Semi Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "#import numpy as np\n",
    "#import keras\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "##from keras.layers.core import Activation\n",
    "#from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers import Convolution2D, MaxPooling2D\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.regularizers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "#epochs = 5\n",
    "\n",
    "#mnist image dimensionality\n",
    "img_rows = 32\n",
    "img_cols = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 102, 1: 112, 2: 99, 3: 92, 4: 99, 5: 85, 6: 107, 7: 102, 8: 99, 9: 103}\n",
      "{0: 488, 1: 505, 2: 512, 3: 497, 4: 507, 5: 488, 6: 491, 7: 495, 8: 504, 9: 513}\n",
      "x_train shape: (1000, 3, 32, 32)\n",
      "x_test shape: (5000, 3, 32, 32)\n",
      "1000 train samples\n",
      "5000 test samples\n",
      "Y_train shape: (1000, 10)\n",
      "Y_test shape: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#loading the mnist dataInit\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "divided_input = np.array_split(X_train, 50)\n",
    "X_train = divided_input[0]\n",
    "\n",
    "\n",
    "divided_output = np.array_split(Y_train, 50)\n",
    "Y_train = divided_output[0]\n",
    "\n",
    "unique, counts = numpy.unique(Y_train, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "divided_inputtest = np.array_split(X_test, 2)\n",
    "X_test = divided_inputtest[0]\n",
    "divided_outputtest = np.array_split(Y_test, 2)\n",
    "Y_test = divided_outputtest[0]\n",
    "\n",
    "unique, counts = numpy.unique(Y_test, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "#reshaping for input to network\n",
    "#X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "#X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "\n",
    "#input_shape = (img_rows, img_cols, 3)\n",
    "input_shape = (3, img_rows, img_cols)\n",
    "\n",
    "#making data float datatype\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#normalizing the data\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#convert class vectors to one hot encoded vectors\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compilation successful\n"
     ]
    }
   ],
   "source": [
    "feature_layers = [\n",
    "    Convolution2D(64, 5, 5, border_mode='same',subsample=(2, 2), input_shape=(3,32,32)),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.5),\n",
    "    Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.5),\n",
    "    Convolution2D(256, 5, 5, border_mode='same', subsample=(2,2)),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.5),\n",
    "    Convolution2D(512, 5, 5, border_mode='same', subsample=(4,4)),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.5),\n",
    "    Flatten()\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(512, W_regularizer=keras.regularizers.l2(0.01), name='fc_layer1'),\n",
    "    Activation('relu'),\n",
    "    Dense(num_classes, activation='softmax', W_regularizer=keras.regularizers.l2(0.01), name='fc_layer2')\n",
    "]\n",
    "'''\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(512, W_regularizer=keras.regularizers.l2(0.01), name='fc_layer1'),\n",
    "    Activation('relu'),\n",
    "    Dense(num_classes, activation='softmax', name='fc_layer2')\n",
    "]\n",
    "'''\n",
    "\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "# different backend has different image dim order, so we need to judge first.\n",
    "\n",
    "'''\n",
    "input_shape = (28,28,1)\n",
    "model.add(Convolution2D(64, 5, 5, border_mode='same',subsample=(2, 2), input_shape=input_shape))\n",
    "#model.add(LeakyReLU(0.02))\n",
    "model.add(Activation('tanh'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, 5, 5, border_mode='same', subsample=(2,2)))\n",
    "#model.add(LeakyReLU(0.02))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "#model.add(LeakyReLU(0.02))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation('sigmoid'))\n",
    "'''\n",
    "#print model.summary()\n",
    "\n",
    "model.load_weights('discriminator_cifar', by_name=True)\n",
    "\n",
    "for l in feature_layers:\n",
    "    l.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Model Compilation successful')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_9 (Convolution2D)  (None, 64, 16, 16)    4864        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)          (None, 64, 16, 16)    0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 16, 16)    0           leakyrelu_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 128, 8, 8)     204928      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)          (None, 128, 8, 8)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128, 8, 8)     0           leakyrelu_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 256, 4, 4)     819456      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_7 (LeakyReLU)          (None, 256, 4, 4)     0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 256, 4, 4)     0           leakyrelu_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 1, 1)     3277312     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_8 (LeakyReLU)          (None, 512, 1, 1)     0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 512, 1, 1)     0           leakyrelu_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 512)           0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "fc_layer1 (Dense)                (None, 512)           262656      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 512)           0           fc_layer1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "fc_layer2 (Dense)                (None, 10)            5130        activation_7[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 4,574,346\n",
      "Trainable params: 267,786\n",
      "Non-trainable params: 4,306,560\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 2s - loss: 6.9628 - acc: 0.1050 - val_loss: 6.1639 - val_acc: 0.1016\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 2s - loss: 5.6570 - acc: 0.0930 - val_loss: 5.0358 - val_acc: 0.1340\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 2s - loss: 4.6496 - acc: 0.1040 - val_loss: 4.1872 - val_acc: 0.1010\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 2s - loss: 3.9047 - acc: 0.1240 - val_loss: 3.5723 - val_acc: 0.1010\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 2s - loss: 3.3715 - acc: 0.1240 - val_loss: 3.1394 - val_acc: 0.1010\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.9994 - acc: 0.1210 - val_loss: 2.8430 - val_acc: 0.1010\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.7483 - acc: 0.1110 - val_loss: 2.6451 - val_acc: 0.1010\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.5817 - acc: 0.1120 - val_loss: 2.5160 - val_acc: 0.1010\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.4740 - acc: 0.1130 - val_loss: 2.4337 - val_acc: 0.1010\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.4059 - acc: 0.1120 - val_loss: 2.3822 - val_acc: 0.1010\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3640 - acc: 0.1130 - val_loss: 2.3507 - val_acc: 0.1010\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3385 - acc: 0.1120 - val_loss: 2.3318 - val_acc: 0.1010\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3235 - acc: 0.1120 - val_loss: 2.3206 - val_acc: 0.1010\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3145 - acc: 0.1120 - val_loss: 2.3141 - val_acc: 0.1010\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3093 - acc: 0.1120 - val_loss: 2.3104 - val_acc: 0.1010\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3062 - acc: 0.1120 - val_loss: 2.3080 - val_acc: 0.1010\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3045 - acc: 0.1120 - val_loss: 2.3067 - val_acc: 0.1010\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3033 - acc: 0.1120 - val_loss: 2.3059 - val_acc: 0.1010\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 2s - loss: 2.3026 - acc: 0.1120 - val_loss: 2.3053 - val_acc: 0.1010\n",
      "Epoch 20/50\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 2.3026 - acc: 0.1027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-11ec88541566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=50,\n\u001b[1;32m----> 2\u001b[1;33m           verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    903\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[0;32m    904\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m                                                    verbose=0)\n\u001b[0m\u001b[0;32m    906\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    988\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=50,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
