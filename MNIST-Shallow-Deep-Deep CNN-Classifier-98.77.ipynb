{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.environ['THEANO_FLAGS'] = \"device=gpu1\"  \n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32,lib.cnmem=1\"\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "import os    \n",
    "#%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import theano\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import *\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.genfromtxt('x_train.out')\n",
    "y_train = np.genfromtxt('y_train.out')\n",
    "vx_train = np.genfromtxt('vx_train.out')\n",
    "vy_train = np.genfromtxt('vy_train.out')\n",
    "x_test = np.genfromtxt('x_test.out')\n",
    "y_test = np.genfromtxt('y_test.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (vx_train.shape)\n",
    "print (vy_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_train=to_categorical(y_train)\n",
    "label_valid=to_categorical(vy_train)\n",
    "label_test= to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (label_train.shape)\n",
    "print (vx_train.shape)\n",
    "print (label_valid.shape)\n",
    "print (x_test.shape)\n",
    "print (label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "#hidden_num_units = 500\n",
    "\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shallow Network\n",
    "model = Sequential([\n",
    "  Dense(output_dim=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    "  Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.3218 - acc: 0.9003 - val_loss: 0.1265 - val_acc: 0.9627\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.1404 - acc: 0.9586 - val_loss: 0.1089 - val_acc: 0.9682\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.1009 - acc: 0.9710 - val_loss: 0.1038 - val_acc: 0.9712\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0881 - acc: 0.9743 - val_loss: 0.1069 - val_acc: 0.9725\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0773 - acc: 0.9778 - val_loss: 0.0834 - val_acc: 0.9771\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0629 - acc: 0.9819 - val_loss: 0.0853 - val_acc: 0.9762\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0599 - acc: 0.9822 - val_loss: 0.0854 - val_acc: 0.9771\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0524 - acc: 0.9847 - val_loss: 0.0792 - val_acc: 0.9791\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0513 - acc: 0.9855 - val_loss: 0.0972 - val_acc: 0.9773\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0464 - acc: 0.9858 - val_loss: 0.1094 - val_acc: 0.9776\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0441 - acc: 0.9878 - val_loss: 0.0820 - val_acc: 0.9810\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0413 - acc: 0.9887 - val_loss: 0.0971 - val_acc: 0.9791\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0359 - acc: 0.9898 - val_loss: 0.0825 - val_acc: 0.9821\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0365 - acc: 0.9902 - val_loss: 0.0938 - val_acc: 0.9802\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0363 - acc: 0.9900 - val_loss: 0.0872 - val_acc: 0.9807\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0360 - acc: 0.9898 - val_loss: 0.0918 - val_acc: 0.9799\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0354 - acc: 0.9900 - val_loss: 0.0832 - val_acc: 0.9820\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0334 - acc: 0.9910 - val_loss: 0.0925 - val_acc: 0.9813\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0288 - acc: 0.9918 - val_loss: 0.0920 - val_acc: 0.9796\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0261 - acc: 0.9930 - val_loss: 0.0836 - val_acc: 0.9835\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0275 - acc: 0.9925 - val_loss: 0.0937 - val_acc: 0.9812\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0277 - acc: 0.9932 - val_loss: 0.1020 - val_acc: 0.9806\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0275 - acc: 0.9917 - val_loss: 0.1004 - val_acc: 0.9816\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 10s - loss: 0.0269 - acc: 0.9928 - val_loss: 0.1044 - val_acc: 0.9825\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s - loss: 0.0260 - acc: 0.9930 - val_loss: 0.1147 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(\n",
    "    x_train, label_train, nb_epoch=epochs, batch_size=batch_size, \n",
    "    validation_data=(vx_train, label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 50s - loss: 0.2616 - acc: 0.9222 - val_loss: 0.1017 - val_acc: 0.9668\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 50s - loss: 0.0681 - acc: 0.9786 - val_loss: 0.0635 - val_acc: 0.9810\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 50s - loss: 0.0470 - acc: 0.9851 - val_loss: 0.0434 - val_acc: 0.9874\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 51s - loss: 0.0376 - acc: 0.9879 - val_loss: 0.0424 - val_acc: 0.9870\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 52s - loss: 0.0312 - acc: 0.9901 - val_loss: 0.0592 - val_acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "#train_x_temp = x_train.reshape(-1, 28, 28, 1)\n",
    "#val_x_temp = vx_train.reshape(-1, 28, 28, 1)\n",
    "#test_x_temp=x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_x_temp = x_train.reshape(-1,1, 28, 28)\n",
    "val_x_temp = vx_train.reshape(-1,1, 28, 28)\n",
    "test_x_temp=x_test.reshape(-1,1, 28, 28)\n",
    "print(train_x_temp.shape)\n",
    "print(val_x_temp.shape)\n",
    "print(test_x_temp.shape)\n",
    "\n",
    "\n",
    "# define vars\n",
    "input_shape = (784,)\n",
    "input_reshape = (1,28, 28)\n",
    "\n",
    "conv_num_filters = 5\n",
    "conv_filter_size = 5\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " #InputLayer(input_shape=input_reshape),\n",
    "\n",
    " Convolution2D(25, 5, 5, border_mode='same',activation='relu',\n",
    "              input_shape=input_reshape),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 5, 5, border_mode='same',activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 4, 4, border_mode='same',activation='relu'),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(train_x_temp, label_train, \n",
    "                               nb_epoch=epochs, batch_size=batch_size, \n",
    "                               validation_data=(val_x_temp, label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#pred = model.predict_classes(x_test)\n",
    "pred = model.predict_classes(test_x_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred= to_categorical(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 digits\n",
      "correct:  9877 wrong:  123 error rate:  1.23 %\n",
      "got correctly  98.77 %\n"
     ]
    }
   ],
   "source": [
    "num=len(label_test)\n",
    "r=0\n",
    "w=0\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(pred[i],label_test[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "print (\"tested \",  num, \"digits\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
