{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n",
      "Using Theano backend.\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import theano\n",
    "from keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer, merge\n",
    "# wow difference between Merge and merge---frustrating\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_train.npy')\n",
    "X_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_test.npy')\n",
    "y_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_train.npy')\n",
    "y_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import *\n",
    "\n",
    "label_train=to_categorical(y_train)\n",
    "label_test= to_categorical(y_test)\n",
    "print (label_train.shape)\n",
    "print (label_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.astype('float32') / 255.\n",
    "x_test = X_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train),3,32,32))\n",
    "x_test = x_test.reshape((len(x_test),3,32,32))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "nb_filters_1 = 96\n",
    "nb_filters_2 = 192\n",
    "nb_filters_3 = 256\n",
    "nb_conv = 1\n",
    "nb_conv_mid = 3\n",
    "nb_conv_init = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv(init, nb_filter, row, col, subsample=(1,1), repeat=0):\n",
    "    c = Convolution2D(nb_filter, row, col, border_mode='same', subsample=subsample)(init)\n",
    "    c = LeakyReLU()(c)\n",
    "\n",
    "    for i in range(repeat):\n",
    "        c = Convolution2D(nb_filter, row, col, border_mode='same', subsample=subsample)(c)\n",
    "        c = LeakyReLU()(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 32, 32)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 96, 32, 32)    7296        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 96, 32, 32)    2688        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_1 (LeakyReLU)          (None, 96, 32, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_3 (LeakyReLU)          (None, 96, 32, 32)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 96, 32, 32)    230496      leakyrelu_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 96, 32, 32)    83040       leakyrelu_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_2 (LeakyReLU)          (None, 96, 32, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_4 (LeakyReLU)          (None, 96, 32, 32)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 192, 32, 32)   0           leakyrelu_2[0][0]                \n",
      "                                                                   leakyrelu_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 96, 16, 16)    460896      merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_5 (LeakyReLU)          (None, 96, 16, 16)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(None, 96, 16, 16)    192         leakyrelu_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 192, 16, 16)   166080      batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 192, 16, 16)   166080      batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_6 (LeakyReLU)          (None, 192, 16, 16)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_8 (LeakyReLU)          (None, 192, 16, 16)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 192, 16, 16)   331968      leakyrelu_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 192, 16, 16)   331968      leakyrelu_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_7 (LeakyReLU)          (None, 192, 16, 16)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_9 (LeakyReLU)          (None, 192, 16, 16)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 384, 16, 16)   0           leakyrelu_7[0][0]                \n",
      "                                                                   leakyrelu_9[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 192, 8, 8)     663744      merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_10 (LeakyReLU)         (None, 192, 8, 8)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 192, 8, 8)     384         leakyrelu_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 256, 8, 8)     442624      batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 256, 8, 8)     49408       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 256, 8, 8)     1229056     batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_11 (LeakyReLU)         (None, 256, 8, 8)     0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_12 (LeakyReLU)         (None, 256, 8, 8)     0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_13 (LeakyReLU)         (None, 256, 8, 8)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 768, 8, 8)     0           leakyrelu_11[0][0]               \n",
      "                                                                   leakyrelu_12[0][0]               \n",
      "                                                                   leakyrelu_13[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 192, 4, 4)     1327296     merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_14 (LeakyReLU)         (None, 192, 4, 4)     0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 192, 4, 4)     0           leakyrelu_14[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 3072)          0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            30730       flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5523946\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init = Input(shape=(3, img_rows, img_cols),)\n",
    "\n",
    "fork11 = conv(init, nb_filters_1, nb_conv_init, nb_conv_init, repeat=1)\n",
    "fork12 = conv(init, nb_filters_1, nb_conv_mid, nb_conv_mid, repeat=1)\n",
    "merge1 = merge([fork11, fork12, ], mode='concat', concat_axis=1)\n",
    "conv_pool1 = conv(merge1, nb_filters_1, nb_conv_init, nb_conv_init, subsample=(2,2))\n",
    "bn1 = BatchNormalization(axis=1)(conv_pool1)\n",
    "\n",
    "fork21 = conv(bn1, nb_filters_2, nb_conv_mid, nb_conv_mid, repeat=1)\n",
    "fork22 = conv(bn1, nb_filters_2, nb_conv_mid, nb_conv_mid, repeat=1)\n",
    "merge2 = merge([fork21, fork22, ], mode='concat', concat_axis=1)\n",
    "conv_pool2 = conv(merge2, nb_filters_2, nb_conv_mid, nb_conv_mid, subsample=(2,2))\n",
    "bn2 = BatchNormalization(axis=1)(conv_pool2)\n",
    "\n",
    "fork31 = conv(bn2, nb_filters_3, nb_conv_mid, nb_conv_mid)\n",
    "fork32 = conv(bn2, nb_filters_3, nb_conv, nb_conv)\n",
    "fork33 = conv(bn2, nb_filters_3, nb_conv_init, nb_conv_init)\n",
    "merge3 = merge([fork31, fork32, fork33, ], mode='concat', concat_axis=1)\n",
    "conv_pool3 = conv(merge3, nb_filters_2, nb_conv_mid, nb_conv_mid, subsample=(2,2))\n",
    "dropout = Dropout(0.5)(conv_pool3)\n",
    "\n",
    "flatten = Flatten()(dropout)\n",
    "output = Dense(10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = Model(input=init, output=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=1, verbose=0),\n",
    "                ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 2226s - loss: 2.5686 - acc: 0.2478 - val_loss: 3.6936 - val_acc: 0.1832\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 2213s - loss: 2.5958 - acc: 0.2717 - val_loss: 3.1052 - val_acc: 0.2740\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 2222s - loss: 2.6973 - acc: 0.2848 - val_loss: 2.6438 - val_acc: 0.2881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb66d2410b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, label_train,\n",
    "            nb_epoch=3,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            validation_data=(x_test, label_test),\n",
    "            callbacks=callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "(10000, 10)\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print (y_pred.size)\n",
    "print (y_pred.shape)\n",
    "print (y_pred.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08579691,  0.07687199,  0.12446834,  0.18162394,  0.10637974,\n",
       "        0.12461416,  0.10059114,  0.09089096,  0.06253739,  0.04622545])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_y_pred=[]\n",
    "for i in range (len(y_pred)):\n",
    "    new_y_pred.append([np.argmax(y_pred[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_y_pred=np.asarray(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (new_y_pred.shape)\n",
    "new_y_pred=to_categorical(new_y_pred)\n",
    "print (new_y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 digits\n",
      "correct:  2749 wrong:  7251 error rate:  72.51 %\n",
      "got correctly  27.49 %\n"
     ]
    }
   ],
   "source": [
    "num=len(y_pred)\n",
    "r=0\n",
    "w=0\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(new_y_pred[i],label_test[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "print (\"tested \",  num, \"digits\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
