{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sknn import mlp\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelBinarizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_train.npy')\n",
    "X_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_test.npy')\n",
    "y_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_train.npy')\n",
    "y_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.astype('float32') / 255.\n",
    "x_test = X_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n_feat = x_train.shape[1]\n",
    "n_targets = y_train.max() + 1\n",
    "print(n_feat)\n",
    "print(n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "def store_stats(avg_valid_error, avg_train_error, **_):\n",
    "    errors.append((avg_valid_error, avg_train_error))\n",
    "    print ('Average Validation Error ',avg_valid_error)\n",
    "    print ('Average Training Error ',avg_train_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#be careful of the humungous verbose\n",
    "def my_callback(event, **variables):\n",
    "    print(event)        # The name of the event, as shown in the list above.\n",
    "    print(variables)    # Full dictionary of local variables from training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#be careful of the humungous verbose\n",
    "def my_callback(**variables):\n",
    "    #print(variables)    # Full dictionary of local variables from training loop.\n",
    "    print('best_params',len(variables['best_params']))\n",
    "    print('best_params 0',len(variables['best_params'][0]))\n",
    "    print('best_params 0 0',len(variables['best_params'][0][0]))\n",
    "    print('best_params 0 1',len(variables['best_params'][0][1]))\n",
    "    print('best_params 1',len(variables['best_params'][1]))\n",
    "    print('best_params 1 0',len(variables['best_params'][1][0]))\n",
    "    print('best_params 1 1',len(variables['best_params'][1][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_callback(**variables):\n",
    "#def my_callback(event, **variables):\n",
    "    #print(event)        # The name of the event, as shown in the list above.\n",
    "    print(variables['y'])    # Full dictionary of local variables from training loop.\n",
    "    print(variables['yb'])\n",
    "    expected=variables['yb']\n",
    "    predicted = variables['y']\n",
    "    num=len(expected)\n",
    "    r=0\n",
    "    w=0\n",
    "    for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(expected[i],predicted[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "    print (\"Trained \",  num, \"Cifar 10 images\")\n",
    "    print (\"correct: \", r, \"wrong: \", w, \"Training error%: \", float(w)*100/(r+w), \"%\")\n",
    "    print (\"Training Accuracy \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000, 3072)\n",
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train[49000:].shape)\n",
    "print (y_train[49000:].shape)\n",
    "print (x_test[9000:].shape)\n",
    "print (y_test[9000:].shape)\n",
    "\n",
    "sample_train = x_train[49000:]\n",
    "sample_test = x_test[9000:]\n",
    "sample_y_train = y_train[49000:]\n",
    "sample_y_test = y_test[9000:]\n",
    "print (sample_train.shape)\n",
    "print (sample_test.shape)\n",
    "print (sample_y_train.shape)\n",
    "print (sample_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n_feat = sample_train.shape[1]\n",
    "n_targets = sample_y_train.max() + 1\n",
    "print(n_feat)\n",
    "print(n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = mlp.Classifier(\n",
    "        layers=[\n",
    "            mlp.Layer(\"Sigmoid\", units=n_feat/16),\n",
    "            mlp.Layer(\"Softmax\", units=n_targets)],\n",
    "        n_iter=1,\n",
    "        n_stable=10,\n",
    "        batch_size=250,\n",
    "        learning_rate=0.002,\n",
    "        learning_rule=\"momentum\",\n",
    "        valid_size=0.1,\n",
    "        verbose=1,\n",
    "        callback={'on_epoch_finish': my_callback}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/lasagne/init.py:99: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  low=self.range[0], high=self.range[1], size=shape))\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params 2\n",
      "best_params 0 2\n",
      "best_params 0 0 3072\n",
      "best_params 0 1 192\n",
      "best_params 1 2\n",
      "best_params 1 0 192\n",
      "best_params 1 1 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=250,\n",
       "      callback={'on_epoch_finish': <function my_callback at 0x7f46a614e9d8>},\n",
       "      debug=False, dropout_rate=None, f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Sigmoid`: frozen=False, units=192.0, name='hidden0'>,\n",
       "      layers=[<sknn.nn.Layer `Sigmoid`: frozen=False, units=192.0, name='hidden0'>, <sknn.nn.Layer `Softmax`: frozen=False, units=10, name='output'>],\n",
       "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
       "      loss_type=None, n_iter=1, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: frozen=False, units=10, name='output'>,\n",
       "      parameters=None, random_state=None, regularize=None,\n",
       "      valid_set=(array([[ 0.61961,  0.55294, ...,  1.     ,  1.     ],\n",
       "       [ 0.71373,  0.76863, ...,  0.61569,  0.58039],\n",
       "       ...,\n",
       "       [ 0.92941,  0.92941, ...,  0.64706,  0.71373],\n",
       "       [ 0.18824,  0.3098 , ...,  0.23137,  0.27451]], dtype=float32), array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  1.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  1.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.]], dtype=float32)),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(sample_train, sample_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = mlp.Classifier(\n",
    "        layers=[\n",
    "            mlp.Layer(\"Tanh\", units=n_feat/8),\n",
    "            mlp.Layer(\"Sigmoid\", units=n_feat/16),\n",
    "            mlp.Layer(\"Softmax\", units=n_targets)],\n",
    "        n_iter=50,\n",
    "        n_stable=10,\n",
    "        batch_size=25,\n",
    "        learning_rate=0.002,\n",
    "        learning_rule=\"momentum\",\n",
    "        valid_size=0.1,\n",
    "        verbose=1,\n",
    "        callback={'on_epoch_finish': store_stats}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/lasagne/init.py:99: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  low=self.range[0], high=self.range[1], size=shape))\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Error  1.83768300056\n",
      "Average Training Error  1.94756979227\n",
      "Average Validation Error  1.7366314137\n",
      "Average Training Error  1.77474173817\n",
      "Average Validation Error  1.69711952567\n",
      "Average Training Error  1.69599910902\n",
      "Average Validation Error  1.6377687192\n",
      "Average Training Error  1.63820813225\n",
      "Average Validation Error  1.60753723919\n",
      "Average Training Error  1.58994910942\n",
      "Average Validation Error  1.57074083149\n",
      "Average Training Error  1.5500730788\n",
      "Average Validation Error  1.56890162289\n",
      "Average Training Error  1.51622480018\n",
      "Average Validation Error  1.56587384909\n",
      "Average Training Error  1.48971211003\n",
      "Average Validation Error  1.51451502413\n",
      "Average Training Error  1.45850133257\n",
      "Average Validation Error  1.49152029604\n",
      "Average Training Error  1.4364023799\n",
      "Average Validation Error  1.45823601097\n",
      "Average Training Error  1.40679898318\n",
      "Average Validation Error  1.4288492018\n",
      "Average Training Error  1.38514340722\n",
      "Average Validation Error  1.46831718445\n",
      "Average Training Error  1.36163778742\n",
      "Average Validation Error  1.42555773437\n",
      "Average Training Error  1.34075666308\n",
      "Average Validation Error  1.43025722712\n",
      "Average Training Error  1.32169652459\n",
      "Average Validation Error  1.40114107966\n",
      "Average Training Error  1.30310287499\n",
      "Average Validation Error  1.37329288781\n",
      "Average Training Error  1.28055274487\n",
      "Average Validation Error  1.37283204824\n",
      "Average Training Error  1.26629644589\n",
      "Average Validation Error  1.42330574125\n",
      "Average Training Error  1.24955137415\n",
      "Average Validation Error  1.40725446314\n",
      "Average Training Error  1.23097586642\n",
      "Average Validation Error  1.39210866183\n",
      "Average Training Error  1.21635921074\n",
      "Average Validation Error  1.37659712791\n",
      "Average Training Error  1.19709410876\n",
      "Average Validation Error  1.35395675361\n",
      "Average Training Error  1.17929998328\n",
      "Average Validation Error  1.40119317472\n",
      "Average Training Error  1.16920760903\n",
      "Average Validation Error  1.36499454975\n",
      "Average Training Error  1.15442121837\n",
      "Average Validation Error  1.37353136271\n",
      "Average Training Error  1.13518114858\n",
      "Average Validation Error  1.32551133633\n",
      "Average Training Error  1.12110950732\n",
      "Average Validation Error  1.35891889215\n",
      "Average Training Error  1.11129704591\n",
      "Average Validation Error  1.3785910663\n",
      "Average Training Error  1.09590217676\n",
      "Average Validation Error  1.34311220169\n",
      "Average Training Error  1.08119231724\n",
      "Average Validation Error  1.44051296085\n",
      "Average Training Error  1.06513916031\n",
      "Average Validation Error  1.37653187156\n",
      "Average Training Error  1.04778523612\n",
      "Average Validation Error  1.3410700956\n",
      "Average Training Error  1.03842229585\n",
      "Average Validation Error  1.3518115598\n",
      "Average Training Error  1.02181937077\n",
      "Average Validation Error  1.41738995761\n",
      "Average Training Error  1.00925552979\n",
      "Average Validation Error  1.37927128047\n",
      "Average Training Error  0.998517739044\n",
      "Average Validation Error  1.34867640734\n",
      "Average Training Error  0.980877680265\n",
      "[(10000, 10)]\n",
      "Classification report for classifier Classifier(batch_size=25,\n",
      "      callback={'on_epoch_finish': <function store_stats at 0x7f31c14bdc80>},\n",
      "      debug=False, dropout_rate=None, f_stable=0.001,\n",
      "      hidden0=<sknn.nn.Layer `Tanh`: units=384.0, name='hidden0', frozen=False>,\n",
      "      hidden1=<sknn.nn.Layer `Sigmoid`: units=192.0, name='hidden1', frozen=False>,\n",
      "      layers=[<sknn.nn.Layer `Tanh`: units=384.0, name='hidden0', frozen=False>, <sknn.nn.Layer `Sigmoid`: units=192.0, name='hidden1', frozen=False>, <sknn.nn.Layer `Softmax`: units=10, name='output', frozen=False>],\n",
      "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
      "      loss_type=None, n_iter=50, n_stable=10, normalize=None,\n",
      "      output=<sknn.nn.Layer `Softmax`: units=10, name='output', frozen=False>,\n",
      "      parameters=None, random_state=None, regularize=None,\n",
      "      valid_set=(array([[ 0.54902,  0.15294, ...,  0.01569,  0.01569],\n",
      "       [ 0.39216,  0.25098, ...,  0.13725,  0.11765],\n",
      "       ...,\n",
      "       [ 0.9098 ,  0.98431, ...,  0.2902 ,  0.30196],\n",
      "       [ 0.14118,  0.14118, ...,  0.27059,  0.30196]], dtype=float32), array([[ 0.,  0., ...,  0.,  0.],\n",
      "       [ 0.,  1., ...,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  1., ...,  0.,  0.],\n",
      "       [ 0.,  0., ...,  1.,  0.]], dtype=float32)),\n",
      "      valid_size=0.1, verbose=1, warning=None, weight_decay=None):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.65      0.59      1000\n",
      "          1       0.65      0.67      0.66      1000\n",
      "          2       0.40      0.50      0.44      1000\n",
      "          3       0.40      0.28      0.33      1000\n",
      "          4       0.45      0.46      0.45      1000\n",
      "          5       0.47      0.35      0.40      1000\n",
      "          6       0.60      0.58      0.59      1000\n",
      "          7       0.54      0.63      0.58      1000\n",
      "          8       0.68      0.64      0.66      1000\n",
      "          9       0.58      0.57      0.57      1000\n",
      "\n",
      "avg / total       0.53      0.53      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[650  25  70  10  34  13  18  30 101  49]\n",
      " [ 56 665  18  10   9  10  18  30  57 127]\n",
      " [ 87  19 496  54 132  51  63  72  11  15]\n",
      " [ 45  19 137 275  75 177 103  88  23  58]\n",
      " [ 64  15 167  36 456  37  91 102  20  12]\n",
      " [ 26   9 141 178  73 352  62 104  24  31]\n",
      " [ 13  16 114  52 120  25 584  40  15  21]\n",
      " [ 54  15  59  44  78  49  15 629  13  44]\n",
      " [135  63  27   9  18  21   9  17 642  59]\n",
      " [ 69 183  24  19  13  14  15  51  43 569]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "expected = y_test\n",
    "predicted = nn.predict(x_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (\n",
    "    nn, classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.8376830005645752, 1.9475697922706603),\n",
       " (1.7366314136981964, 1.7747417381736967),\n",
       " (1.6971195256710052, 1.6959991090165245),\n",
       " (1.6377687191963195, 1.6382081322537527),\n",
       " (1.6075372391939162, 1.5899491094218361),\n",
       " (1.5707408314943314, 1.550073078804546),\n",
       " (1.5689016228914261, 1.5162248001827134),\n",
       " (1.5658738490939141, 1.4897121100293265),\n",
       " (1.514515024125576, 1.4585013325677978),\n",
       " (1.4915202960371972, 1.4364023799035284),\n",
       " (1.4582360109686852, 1.406798983183172),\n",
       " (1.4288492017984391, 1.3851434072189861),\n",
       " (1.4683171844482421, 1.3616377874215444),\n",
       " (1.4255577343702317, 1.3407566630840302),\n",
       " (1.4302572271227836, 1.3216965245869425),\n",
       " (1.4011410796642303, 1.3031028749876552),\n",
       " (1.3732928878068924, 1.2805527448654175),\n",
       " (1.3728320482373237, 1.2662964458929167),\n",
       " (1.423305741250515, 1.249551374150647),\n",
       " (1.4072544631361961, 1.23097586641709),\n",
       " (1.3921086618304253, 1.2163592107428445),\n",
       " (1.3765971279144287, 1.1970941087603568),\n",
       " (1.3539567536115646, 1.1792999832828839),\n",
       " (1.4011931747198105, 1.1692076090309356),\n",
       " (1.3649945497512816, 1.1544212183687421),\n",
       " (1.3735313627123833, 1.1351811485820347),\n",
       " (1.3255113363265991, 1.1211095073156887),\n",
       " (1.3589188921451569, 1.1112970459130076),\n",
       " (1.3785910663008689, 1.0959021767642763),\n",
       " (1.3431122016906738, 1.081192317240768),\n",
       " (1.4405129608511924, 1.0651391603052616),\n",
       " (1.3765318715572357, 1.0477852361235354),\n",
       " (1.3410700955986976, 1.0384222958485285),\n",
       " (1.3518115597963334, 1.0218193707697922),\n",
       " (1.4173899576067925, 1.0092555297911168),\n",
       " (1.3792712804675102, 0.99851773904429542),\n",
       " (1.3486764073371886, 0.98087768026524125)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected=np.reshape(expected,(10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [0],\n",
       "       ..., \n",
       "       [3],\n",
       "       [2],\n",
       "       [7]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 Cifar 10 images\n",
      "correct:  5318 wrong:  4682 error rate:  46.82 %\n",
      "got correctly  53.18 %\n"
     ]
    }
   ],
   "source": [
    "num=len(expected)\n",
    "r=0\n",
    "w=0\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(expected[i],predicted[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "print (\"tested \",  num, \"Cifar 10 images\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
