{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n",
      "Using Theano backend.\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import theano\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer, Merge\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the raw data\n",
    "x_train = np.genfromtxt('x_train.out')\n",
    "y_train = np.genfromtxt('y_train.out')\n",
    "vx_train = np.genfromtxt('vx_train.out')\n",
    "vy_train = np.genfromtxt('vy_train.out')\n",
    "x_test = np.genfromtxt('x_test.out')\n",
    "y_test = np.genfromtxt('y_test.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (vx_train.shape)\n",
    "print (vy_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/utils/np_utils.py:14: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Y = np.zeros((len(y), nb_classes))\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/utils/np_utils.py:16: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Y[i, y[i]] = 1.\n"
     ]
    }
   ],
   "source": [
    "label_train=to_categorical(y_train)\n",
    "label_valid=to_categorical(vy_train)\n",
    "label_test= to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (label_train.shape)\n",
    "print (vx_train.shape)\n",
    "print (label_valid.shape)\n",
    "print (x_test.shape)\n",
    "print (label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# reshape data for CNN \n",
    "\n",
    "#train_x_temp = x_train.reshape(-1, 28, 28, 1)\n",
    "#val_x_temp = vx_train.reshape(-1, 28, 28, 1)\n",
    "#test_x_temp=x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_x_temp = x_train.reshape(-1,1, 28, 28)\n",
    "val_x_temp = vx_train.reshape(-1,1, 28, 28)\n",
    "test_x_temp=x_test.reshape(-1,1, 28, 28)\n",
    "print(train_x_temp.shape)\n",
    "print(val_x_temp.shape)\n",
    "print(test_x_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model parameters and model architecture\n",
    "input_shape = (784,)\n",
    "input_reshape1 = (1,28, 28)\n",
    "conv_num_filters = 25\n",
    "conv_filter_size = 5\n",
    "pool_size = (2, 2)\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "# refer architecture from DCCNN paper\n",
    "left_branch1 = Sequential()\n",
    "left_branch1.add(Convolution2D(64, 5, 5, border_mode='same',activation='relu',input_shape=input_reshape1))\n",
    "right_branch1 = Sequential()\n",
    "right_branch1.add(Convolution2D(64, 5, 5, border_mode='same',activation='relu',input_shape=input_reshape1))\n",
    "merged1 = Merge([left_branch1, right_branch1], mode='ave')\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(merged1)\n",
    "model1.add(MaxPooling2D(pool_size=pool_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_143 (Convolution2D)(None, 64, 28, 28)    1664        convolution2d_input_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_144 (Convolution2D)(None, 64, 28, 28)    1664        convolution2d_input_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_66 (MaxPooling2D)   (None, 64, 14, 14)    0           merge_78[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 3328\n",
      "____________________________________________________________________________________________________\n",
      "Model 1 None\n"
     ]
    }
   ],
   "source": [
    "print ('Model 1',model1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_reshape2 = (64, 14, 14)\n",
    "left_branch2 = Sequential()\n",
    "left_branch2.add(Convolution2D(128, 4, 4, border_mode='same',activation='relu',input_shape=input_reshape2))\n",
    "#left_branch2.add(Convolution2D(128, 4, 4, border_mode='same',activation='relu')) - error\n",
    "\n",
    "right_branch2 = Sequential()\n",
    "right_branch2.add(Convolution2D(128, 4, 4, border_mode='same',activation='relu',input_shape=input_reshape2))\n",
    "#right_branch2.add(Convolution2D(128, 4, 4, border_mode='same',activation='relu')) - error\n",
    "\n",
    "merged2 = Merge([left_branch2, right_branch2], mode='ave')\n",
    "model2 = Sequential()\n",
    "model2.add(merged2)\n",
    "model2.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_145 (Convolution2D)(None, 128, 14, 14)   131200      convolution2d_input_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_146 (Convolution2D)(None, 128, 14, 14)   131200      convolution2d_input_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_67 (MaxPooling2D)   (None, 128, 7, 7)     0           merge_79[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 262400\n",
      "____________________________________________________________________________________________________\n",
      "Model 2 None\n"
     ]
    }
   ],
   "source": [
    "print ('Model 2',model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Layer sequential_249 expects 2 inputs, but it received 1 input tensors. Input received: Reshape{2}.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-43d49f134c6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_num_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    143\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 raise Exception('All layers in a Sequential model '\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;31m# raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;31m# with the input_spec set at build time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[1;31m# build and connect layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0minput_added\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mrafi123/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    358\u001b[0m                                 \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                                 \u001b[1;34m' input tensors. Input received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                                 str(input))\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Layer sequential_249 expects 2 inputs, but it received 1 input tensors. Input received: Reshape{2}.0"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(model1)\n",
    "model.add(Flatten())\n",
    "model.add(model2)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=output_num_units, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfold=5\n",
    "nb_epoch=50\n",
    "batch_size=256\n",
    "random_state =335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold_weights_path = os.path.join('mnist_weights_kfold_' + str(nfold) + \n",
    "                                  '_epoch_'+str(nb_epoch)+\n",
    "                                  '_batch_'+str(batch_size) +\n",
    "                                  '_encoded_'+str(encoding_dim) +\n",
    "                                  '.h5')\n",
    "print(kfold_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(x_train), n_folds=nfold, shuffle=True, random_state=random_state)\n",
    "#kf = KFold(len(x_train), n_folds=nfold, shuffle=False, random_state=random_state)\n",
    "#Shuffle false give very high training loss and very low val loss - indicating unknown fit\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_full_encoded_imgs = np.zeros(shape=[x_train.shape[0],encoding_dim])\n",
    "print(train_full_encoded_imgs.shape)\n",
    "print(x_test.shape)\n",
    "test_full_encoded_imgs = np.zeros(shape=[x_test.shape[0],encoding_dim])\n",
    "test_full_decoded_imgs = np.zeros(shape=[x_test.shape[0],x_test.shape[1]])\n",
    "print(test_full_encoded_imgs.shape)\n",
    "print(test_full_decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.path.isfile(kfold_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable this for avoiding using pretrained weights\n",
    "if os.path.isfile(kfold_weights_path):\n",
    "    print ('Loading weights already stored...')\n",
    "    model.load_weights(kfold_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_fold = 0\n",
    "restore_from_last_checkpoint=0\n",
    "for train_index,valid_index in kf:\n",
    "    s_train,s_valid  = x_train[train_index], x_train[valid_index]\n",
    "    \n",
    "    noise_factor = 0.3\n",
    "    s_train_noisy = s_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=s_train.shape) \n",
    "    s_valid_noisy = s_valid + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=s_valid.shape) \n",
    "\n",
    "    s_train_noisy = np.clip(s_train_noisy, 0., 1.)\n",
    "    s_valid_noisy = np.clip(s_valid_noisy, 0., 1.)\n",
    "    #y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    num_fold += 1\n",
    "    print('\\n\\nStart KFold number {} from {}'.format(num_fold, nfold))\n",
    "    print('Split train: ', len(s_train_noisy), len(s_train))\n",
    "    print('Split valid: ', len(s_valid_noisy), len(s_valid))\n",
    "\n",
    "    if not os.path.isfile(kfold_weights_path) or restore_from_last_checkpoint == 0:\n",
    "        callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "                ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "        ]\n",
    "        trained_model_conv = model.fit(train_x_temp, label_train, \n",
    "                               nb_epoch=epochs, \n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               validation_data=(val_x_temp, label_valid),\n",
    "                               callbacks=callbacks)\n",
    "        \n",
    "      \n",
    "    # Store train predictions\n",
    "    train_encoded_imgs = encoder.predict(x_train,batch_size=batch_size, verbose=1)\n",
    "    train_full_encoded_imgs = np.add(train_full_encoded_imgs,train_encoded_imgs)\n",
    "\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_encoded_imgs = encoder.predict(x_test,batch_size=batch_size, verbose=1)\n",
    "    #full_encoded_imgs = np.vstack([full_encoded_imgs,encoded_imgs])\n",
    "    test_full_encoded_imgs = np.add(test_full_encoded_imgs,test_encoded_imgs)\n",
    "    #full_encoded_imgs.append(encoded_imgs)\n",
    "    #print(full_encoded_imgs.shape)\n",
    "    \n",
    "    test_decoded_imgs = decoder.predict(test_encoded_imgs,batch_size=batch_size, verbose=1)\n",
    "    #full_decoded_imgs = np.vstack([full_decoded_imgs,decoded_imgs])\n",
    "    test_full_decoded_imgs = np.add(test_full_decoded_imgs,test_decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res_encoded_imgs = test_full_encoded_imgs/nfold\n",
    "test_res_decoded_imgs = test_full_decoded_imgs/nfold\n",
    "print(test_res_encoded_imgs.shape)\n",
    "print(test_res_decoded_imgs.shape)\n",
    "print(test_res_encoded_imgs)\n",
    "print(test_res_decoded_imgs)\n",
    "train_res_encoded_imgs = train_full_encoded_imgs/nfold\n",
    "print(train_res_encoded_imgs.shape)\n",
    "print(train_res_encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    #ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(s_train_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#pred = model.predict_classes(x_test)\n",
    "pred = model.predict_classes(test_x_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred= to_categorical(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 digits\n",
      "correct:  9877 wrong:  123 error rate:  1.23 %\n",
      "got correctly  98.77 %\n"
     ]
    }
   ],
   "source": [
    "num=len(label_test)\n",
    "r=0\n",
    "w=0\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(pred[i],label_test[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "print (\"tested \",  num, \"digits\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
