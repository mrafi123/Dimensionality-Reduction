{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sknn import mlp\n",
    "from sknn.mlp import Classifier, Convolution, Layer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,LabelBinarizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_train.npy')\n",
    "X_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/X_test.npy')\n",
    "y_train=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_train.npy')\n",
    "y_test=np.load('/media/mrafi123/UStore/Dimensionality-Reduction/data/CIFAR10/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.astype('float32') / 255.\n",
    "x_test = X_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n_feat = x_train.shape[1]\n",
    "n_targets = y_train.max() + 1\n",
    "print(n_feat)\n",
    "print(n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "def store_stats(avg_valid_error, avg_train_error, **_):\n",
    "    errors.append((avg_valid_error, avg_train_error))\n",
    "    print ('Average Validation Error ',avg_valid_error)\n",
    "    print ('Average Training Error ',avg_train_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#be careful of the humungous verbose\n",
    "def my_callback(event, **variables):\n",
    "    print(event)        # The name of the event, as shown in the list above.\n",
    "    print(variables)    # Full dictionary of local variables from training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#be careful of the humungous verbose\n",
    "def my_callback(**variables):\n",
    "    #print(variables)    # Full dictionary of local variables from training loop.\n",
    "    print('best_params',len(variables['best_params']))\n",
    "    print('best_params 0',len(variables['best_params'][0]))\n",
    "    print('best_params 0 0',len(variables['best_params'][0][0]))\n",
    "    print('best_params 0 1',len(variables['best_params'][0][1]))\n",
    "    print('best_params 1',len(variables['best_params'][1]))\n",
    "    print('best_params 1 0',len(variables['best_params'][1][0]))\n",
    "    print('best_params 1 1',len(variables['best_params'][1][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_callback(**variables):\n",
    "#def my_callback(event, **variables):\n",
    "    #print(event)        # The name of the event, as shown in the list above.\n",
    "    print(variables['y'])    # Full dictionary of local variables from training loop.\n",
    "    print(variables['yb'])\n",
    "    expected=variables['yb']\n",
    "    predicted = variables['y']\n",
    "    num=len(expected)\n",
    "    r=0\n",
    "    w=0\n",
    "    for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(expected[i],predicted[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "    print (\"Trained \",  num, \"Cifar 10 images\")\n",
    "    print (\"correct: \", r, \"wrong: \", w, \"Training error%: \", float(w)*100/(r+w), \"%\")\n",
    "    print (\"Training Accuracy \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000, 3072)\n",
      "(1000, 3072)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train[49000:].shape)\n",
    "print (y_train[49000:].shape)\n",
    "print (x_test[9000:].shape)\n",
    "print (y_test[9000:].shape)\n",
    "\n",
    "sample_train = x_train[49000:]\n",
    "sample_test = x_test[9000:]\n",
    "sample_y_train = y_train[49000:]\n",
    "sample_y_test = y_test[9000:]\n",
    "print (sample_train.shape)\n",
    "print (sample_test.shape)\n",
    "print (sample_y_train.shape)\n",
    "print (sample_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-134814f4b187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mn_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_y_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_feat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_feat = sample_train.shape[1]\n",
    "n_targets = sample_y_train.max() + 1\n",
    "print(n_feat)\n",
    "print(n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplenn = mlp.Classifier(\n",
    "        layers=[\n",
    "            mlp.Layer(\"Sigmoid\", units=n_feat/16),\n",
    "            mlp.Layer(\"Softmax\", units=n_targets)],\n",
    "        n_iter=1,\n",
    "        n_stable=10,\n",
    "        batch_size=250,\n",
    "        learning_rate=0.002,\n",
    "        learning_rule=\"momentum\",\n",
    "        valid_size=0.1,\n",
    "        verbose=1,\n",
    "        callback={'on_epoch_finish': my_callback}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/lasagne/init.py:99: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  low=self.range[0], high=self.range[1], size=shape))\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params 2\n",
      "best_params 0 2\n",
      "best_params 0 0 3072\n",
      "best_params 0 1 192\n",
      "best_params 1 2\n",
      "best_params 1 0 192\n",
      "best_params 1 1 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=250,\n",
       "      callback={'on_epoch_finish': <function my_callback at 0x7f46a614e9d8>},\n",
       "      debug=False, dropout_rate=None, f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Sigmoid`: frozen=False, units=192.0, name='hidden0'>,\n",
       "      layers=[<sknn.nn.Layer `Sigmoid`: frozen=False, units=192.0, name='hidden0'>, <sknn.nn.Layer `Softmax`: frozen=False, units=10, name='output'>],\n",
       "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
       "      loss_type=None, n_iter=1, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: frozen=False, units=10, name='output'>,\n",
       "      parameters=None, random_state=None, regularize=None,\n",
       "      valid_set=(array([[ 0.61961,  0.55294, ...,  1.     ,  1.     ],\n",
       "       [ 0.71373,  0.76863, ...,  0.61569,  0.58039],\n",
       "       ...,\n",
       "       [ 0.92941,  0.92941, ...,  0.64706,  0.71373],\n",
       "       [ 0.18824,  0.3098 , ...,  0.23137,  0.27451]], dtype=float32), array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  1.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  1.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.]], dtype=float32)),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(sample_train, sample_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnn = mlp.Classifier(\n",
    "        layers=[\n",
    "            mlp.Layer(\"Rectifier\", units=1500),\n",
    "            mlp.Layer(\"Rectifier\", units=750),\n",
    "            mlp.Layer(\"Rectifier\", units=350),\n",
    "            mlp.Layer(\"Rectifier\", units=150),\n",
    "            mlp.Layer(\"Softmax\", units=n_targets)],\n",
    "        n_iter=25,\n",
    "        n_stable=10,\n",
    "        batch_size=25,\n",
    "        learning_rate=0.002,\n",
    "        learning_rule=\"momentum\",\n",
    "        valid_size=0.1,\n",
    "        verbose=1,\n",
    "        callback={'on_epoch_finish': store_stats}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train),32,32,3))\n",
    "x_test = x_test.reshape((len(x_test),32,32,3))\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Convolution, Layer\n",
    "# Deep CNN Architecture from Karpathy JS demo in CIFAR10\n",
    "dcnn = Classifier(\n",
    "    layers=[\n",
    "        Convolution(\"Rectifier\", channels=16, kernel_shape=(5,5),border_mode='full',pool_shape=(2,2)),\n",
    "        Convolution(\"Rectifier\", channels=20, kernel_shape=(5,5),border_mode='full',pool_shape=(2,2)),\n",
    "        Convolution(\"Rectifier\", channels=20, kernel_shape=(5,5),border_mode='full',pool_shape=(2,2)),\n",
    "        Layer('Rectifier', units=64),\n",
    "        Layer(\"Softmax\",units=n_targets)],\n",
    "        n_iter=160,\n",
    "        n_stable=10,\n",
    "        batch_size=25,\n",
    "        learning_rate=0.002,\n",
    "        learning_rule=\"momentum\",\n",
    "        valid_size=0.1,\n",
    "        verbose=1,\n",
    "        callback={'on_epoch_finish': store_stats}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "/home/mrafi123/anaconda3/lib/python3.5/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Error  2.13139769197\n",
      "Average Training Error  2.21702644361\n",
      "Average Validation Error  2.00949050725\n",
      "Average Training Error  2.06345539424\n",
      "Average Validation Error  1.93037887871\n",
      "Average Training Error  1.96265527275\n",
      "Average Validation Error  1.86741361022\n",
      "Average Training Error  1.88665998532\n",
      "Average Validation Error  1.8192131865\n",
      "Average Training Error  1.83021255354\n",
      "Average Validation Error  1.77397949398\n",
      "Average Training Error  1.7859295706\n",
      "Average Validation Error  1.74087003648\n",
      "Average Training Error  1.7501551089\n",
      "Average Validation Error  1.72885021687\n",
      "Average Training Error  1.71876978808\n",
      "Average Validation Error  1.68984403491\n",
      "Average Training Error  1.69105318513\n",
      "Average Validation Error  1.66911869884\n",
      "Average Training Error  1.66597346683\n",
      "Average Validation Error  1.64969876289\n",
      "Average Training Error  1.64418645084\n",
      "Average Validation Error  1.62939418674\n",
      "Average Training Error  1.6242887195\n",
      "Average Validation Error  1.61686390102\n",
      "Average Training Error  1.60574186378\n",
      "Average Validation Error  1.62173936367\n",
      "Average Training Error  1.58962667773\n",
      "Average Validation Error  1.57894497037\n",
      "Average Training Error  1.57417846302\n",
      "Average Validation Error  1.57307463646\n",
      "Average Training Error  1.55981567012\n",
      "Average Validation Error  1.55890765369\n",
      "Average Training Error  1.54869677229\n",
      "Average Validation Error  1.54804870248\n",
      "Average Training Error  1.53619900154\n",
      "Average Validation Error  1.54638947487\n",
      "Average Training Error  1.52410868595\n",
      "Average Validation Error  1.53031627893\n",
      "Average Training Error  1.51439785288\n",
      "Average Validation Error  1.53421379924\n",
      "Average Training Error  1.50616582665\n",
      "Average Validation Error  1.51036266088\n",
      "Average Training Error  1.49768686752\n",
      "Average Validation Error  1.50516462147\n",
      "Average Training Error  1.48842813949\n",
      "Average Validation Error  1.49708945155\n",
      "Average Training Error  1.48204534627\n",
      "Average Validation Error  1.49025436938\n",
      "Average Training Error  1.47382398592\n",
      "Average Validation Error  1.49958821416\n",
      "Average Training Error  1.46738312297\n",
      "Average Validation Error  1.48653346658\n",
      "Average Training Error  1.4602921571\n",
      "Average Validation Error  1.47917989284\n",
      "Average Training Error  1.45411221782\n",
      "Average Validation Error  1.49095475674\n",
      "Average Training Error  1.44774189032\n",
      "Average Validation Error  1.48532753378\n",
      "Average Training Error  1.44228645729\n",
      "Average Validation Error  1.46886098504\n",
      "Average Training Error  1.43833872765\n",
      "Average Validation Error  1.4877185148\n",
      "Average Training Error  1.43325132135\n",
      "Average Validation Error  1.45485466301\n",
      "Average Training Error  1.42746059189\n",
      "Average Validation Error  1.44382310331\n",
      "Average Training Error  1.42100721618\n",
      "Average Validation Error  1.45573753357\n",
      "Average Training Error  1.4173200651\n",
      "Average Validation Error  1.43356530368\n",
      "Average Training Error  1.41300319301\n",
      "Average Validation Error  1.47135357082\n",
      "Average Training Error  1.40923013237\n",
      "Average Validation Error  1.43409707129\n",
      "Average Training Error  1.40514577955\n",
      "Average Validation Error  1.43234501779\n",
      "Average Training Error  1.39936456097\n",
      "Average Validation Error  1.42909208953\n",
      "Average Training Error  1.39557492269\n",
      "Average Validation Error  1.42518904388\n",
      "Average Training Error  1.39243241191\n",
      "Average Validation Error  1.41732318461\n",
      "Average Training Error  1.38966734952\n",
      "Average Validation Error  1.41197299689\n",
      "Average Training Error  1.38508173029\n",
      "Average Validation Error  1.41895905972\n",
      "Average Training Error  1.38094177223\n",
      "Average Validation Error  1.42366915345\n",
      "Average Training Error  1.37790618926\n",
      "Average Validation Error  1.409126513\n",
      "Average Training Error  1.3751879549\n",
      "Average Validation Error  1.41780980736\n",
      "Average Training Error  1.37041772664\n",
      "Average Validation Error  1.41078796059\n",
      "Average Training Error  1.36855085333\n",
      "Average Validation Error  1.39560166538\n",
      "Average Training Error  1.36671290865\n",
      "Average Validation Error  1.39497946769\n",
      "Average Training Error  1.35962824119\n",
      "Average Validation Error  1.38951477826\n",
      "Average Training Error  1.35800703314\n",
      "Average Validation Error  1.39357385218\n",
      "Average Training Error  1.35549471206\n",
      "Average Validation Error  1.39468831748\n",
      "Average Training Error  1.35279909773\n",
      "Average Validation Error  1.39310804009\n",
      "Average Training Error  1.3496175669\n",
      "Average Validation Error  1.39094249249\n",
      "Average Training Error  1.34743763245\n",
      "Average Validation Error  1.38212840319\n",
      "Average Training Error  1.34490911225\n",
      "Average Validation Error  1.380427773\n",
      "Average Training Error  1.34174410098\n",
      "Average Validation Error  1.38136253744\n",
      "Average Training Error  1.33764633725\n",
      "Average Validation Error  1.37185114384\n",
      "Average Training Error  1.33606658343\n",
      "Average Validation Error  1.370235838\n",
      "Average Training Error  1.33341845307\n",
      "Average Validation Error  1.39442130536\n",
      "Average Training Error  1.33250396775\n",
      "Average Validation Error  1.36913315445\n",
      "Average Training Error  1.32801943551\n",
      "Average Validation Error  1.3958667779\n",
      "Average Training Error  1.32417185936\n",
      "Average Validation Error  1.36609867841\n",
      "Average Training Error  1.32320102145\n",
      "Average Validation Error  1.38106550127\n",
      "Average Training Error  1.31830203311\n",
      "Average Validation Error  1.35738145232\n",
      "Average Training Error  1.31855390754\n",
      "Average Validation Error  1.36683419436\n",
      "Average Training Error  1.31587194595\n",
      "Average Validation Error  1.36572111875\n",
      "Average Training Error  1.31203296191\n",
      "Average Validation Error  1.36797431171\n",
      "Average Training Error  1.31197304431\n",
      "Average Validation Error  1.4004514578\n",
      "Average Training Error  1.30957444814\n",
      "Average Validation Error  1.36926528782\n",
      "Average Training Error  1.30666428215\n",
      "Average Validation Error  1.36689907491\n",
      "Average Training Error  1.30317728235\n",
      "Average Validation Error  1.36402186036\n",
      "Average Training Error  1.3046317832\n",
      "Average Validation Error  1.35679675013\n",
      "Average Training Error  1.30169105222\n",
      "Average Validation Error  1.35606772184\n",
      "Average Training Error  1.2995201632\n",
      "Average Validation Error  1.35972076207\n",
      "Average Training Error  1.29746374415\n",
      "Average Validation Error  1.36073636919\n",
      "Average Training Error  1.29269323041\n",
      "Average Validation Error  1.35288078845\n",
      "Average Training Error  1.29205096583\n",
      "Average Validation Error  1.3522732386\n",
      "Average Training Error  1.290726136\n",
      "Average Validation Error  1.35250426173\n",
      "Average Training Error  1.28784840802\n",
      "Average Validation Error  1.34649635494\n",
      "Average Training Error  1.2859699191\n",
      "Average Validation Error  1.33582080364\n",
      "Average Training Error  1.28512063315\n",
      "Average Validation Error  1.33074790448\n",
      "Average Training Error  1.28170775712\n",
      "Average Validation Error  1.33758889556\n",
      "Average Training Error  1.27846836954\n",
      "Average Validation Error  1.33933322668\n",
      "Average Training Error  1.27925993267\n",
      "Average Validation Error  1.35980402619\n",
      "Average Training Error  1.27862979091\n",
      "Average Validation Error  1.34437990189\n",
      "Average Training Error  1.27585318887\n",
      "Average Validation Error  1.34131331384\n",
      "Average Training Error  1.27412862072\n",
      "Average Validation Error  1.34844120532\n",
      "Average Training Error  1.27232170095\n",
      "Average Validation Error  1.35728166133\n",
      "Average Training Error  1.26979648451\n",
      "Average Validation Error  1.32900432408\n",
      "Average Training Error  1.26834917698\n",
      "Average Validation Error  1.32175351024\n",
      "Average Training Error  1.26537413299\n",
      "Average Validation Error  1.32326663285\n",
      "Average Training Error  1.2644711506\n",
      "Average Validation Error  1.35334379435\n",
      "Average Training Error  1.26203976091\n",
      "Average Validation Error  1.32485317826\n",
      "Average Training Error  1.26335504982\n",
      "Average Validation Error  1.33520713657\n",
      "Average Training Error  1.25973475267\n",
      "Average Validation Error  1.31562450707\n",
      "Average Training Error  1.25812407119\n",
      "Average Validation Error  1.33030562878\n",
      "Average Training Error  1.25466314067\n",
      "Average Validation Error  1.34392484874\n",
      "Average Training Error  1.2547218643\n",
      "Average Validation Error  1.33564690828\n",
      "Average Training Error  1.25319617626\n",
      "Average Validation Error  1.30736353487\n",
      "Average Training Error  1.25109986024\n",
      "Average Validation Error  1.34423167676\n",
      "Average Training Error  1.24902166363\n",
      "Average Validation Error  1.31144754916\n",
      "Average Training Error  1.24978430818\n",
      "Average Validation Error  1.35347073585\n",
      "Average Training Error  1.24694837259\n",
      "Average Validation Error  1.33699709177\n",
      "Average Training Error  1.24845359147\n",
      "Average Validation Error  1.32436227679\n",
      "Average Training Error  1.24411362406\n",
      "Average Validation Error  1.31362983823\n",
      "Average Training Error  1.24308510221\n",
      "Average Validation Error  1.3062550199\n",
      "Average Training Error  1.23947587772\n",
      "Average Validation Error  1.33241672039\n",
      "Average Training Error  1.23945264677\n",
      "Average Validation Error  1.31654448032\n",
      "Average Training Error  1.23985443208\n",
      "Average Validation Error  1.30744355887\n",
      "Average Training Error  1.23672549122\n",
      "Average Validation Error  1.34195411742\n",
      "Average Training Error  1.23413804183\n",
      "Average Validation Error  1.31667523503\n",
      "Average Training Error  1.23390907622\n",
      "Average Validation Error  1.31913674593\n",
      "Average Training Error  1.23202272707\n",
      "Average Validation Error  1.33822780788\n",
      "Average Training Error  1.23089013759\n",
      "Average Validation Error  1.34032917351\n",
      "Average Training Error  1.22911163578\n",
      "Average Validation Error  1.31884506255\n",
      "Average Training Error  1.22887457331\n",
      "Average Validation Error  1.30197006881\n",
      "Average Training Error  1.22717230098\n",
      "Average Validation Error  1.30707608879\n",
      "Average Training Error  1.22424796402\n",
      "Average Validation Error  1.29684618533\n",
      "Average Training Error  1.22385715581\n",
      "Average Validation Error  1.32756863922\n",
      "Average Training Error  1.2241336148\n",
      "Average Validation Error  1.30883083016\n",
      "Average Training Error  1.22220842126\n",
      "Average Validation Error  1.2967635569\n",
      "Average Training Error  1.21995313048\n",
      "Average Validation Error  1.30551720291\n",
      "Average Training Error  1.22003755616\n",
      "Average Validation Error  1.30221026897\n",
      "Average Training Error  1.2165142003\n",
      "Average Validation Error  1.31936679482\n",
      "Average Training Error  1.21608233929\n",
      "Average Validation Error  1.32000890523\n",
      "Average Training Error  1.21445906957\n",
      "Average Validation Error  1.31618146271\n",
      "Average Training Error  1.21405772295\n",
      "Average Validation Error  1.30400104225\n",
      "Average Training Error  1.21095518672\n",
      "Average Validation Error  1.31304471761\n",
      "Average Training Error  1.21310991055\n",
      "Average Validation Error  1.30837035775\n",
      "Average Training Error  1.2093332489\n",
      "Average Validation Error  1.299945575\n",
      "Average Training Error  1.20761110302\n",
      "Average Validation Error  1.30391080499\n",
      "Average Training Error  1.204915624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=25,\n",
       "      callback={'on_epoch_finish': <function store_stats at 0x7f69b0035d90>},\n",
       "      debug=False, dropout_rate=None, f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden1=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden2=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden2', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden3=<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden3', units=64>,\n",
       "      layers=[<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>, <sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride...=False, name='hidden3', units=64>, <sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>],\n",
       "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
       "      loss_type=None, n_iter=160, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>,\n",
       "      parameters=None, random_state=None, regularize=None,\n",
       "      valid_set=(array([[[[ 0.65882,  0.50196, ...,  0.6549 ,  0.6549 ],\n",
       "         [ 0.68235,  0.58431, ...,  0.6549 ,  0.68235],\n",
       "         ...,\n",
       "         [ 0.52157,  0.49412, ...,  0.7098 ,  0.73725],\n",
       "         [ 0.5098 ,  0.4902 , ...,  0.56078,  0.58039]],\n",
       "\n",
       "        [[ 0.79216,  0.67843, ...,  0.85098,  0....],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  1., ...,  0.,  0.]], dtype=float32)),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcnn.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=25,\n",
       "      callback={'on_epoch_finish': <function store_stats at 0x7f69b0035d90>},\n",
       "      debug=False, dropout_rate=None, f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden1=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden2=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden2', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
       "      hidden3=<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden3', units=64>,\n",
       "      layers=[<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>, <sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride...=False, name='hidden3', units=64>, <sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>],\n",
       "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
       "      loss_type=None, n_iter=160, n_stable=10, normalize=None,\n",
       "      output=<sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>,\n",
       "      parameters=None, random_state=None, regularize=None,\n",
       "      valid_set=(array([[[[ 0.65882,  0.50196, ...,  0.6549 ,  0.6549 ],\n",
       "         [ 0.68235,  0.58431, ...,  0.6549 ,  0.68235],\n",
       "         ...,\n",
       "         [ 0.52157,  0.49412, ...,  0.7098 ,  0.73725],\n",
       "         [ 0.5098 ,  0.4902 , ...,  0.56078,  0.58039]],\n",
       "\n",
       "        [[ 0.79216,  0.67843, ...,  0.85098,  0....],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  1., ...,  0.,  0.]], dtype=float32)),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10000, 10)]\n",
      "Classification report for classifier Classifier(batch_size=25,\n",
      "      callback={'on_epoch_finish': <function store_stats at 0x7f69b0035d90>},\n",
      "      debug=False, dropout_rate=None, f_stable=0.001,\n",
      "      hidden0=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>,\n",
      "      hidden1=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
      "      hidden2=<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden2', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=20, border_mode='full', kernel_shape=(5, 5)>,\n",
      "      hidden3=<sknn.nn.Layer `Rectifier`: frozen=False, name='hidden3', units=64>,\n",
      "      layers=[<sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden0', kernel_stride=(1, 1), pool_shape=(2, 2), scale_factor=(1, 1), channels=16, border_mode='full', kernel_shape=(5, 5)>, <sknn.nn.Convolution `Rectifier`: frozen=False, pool_type='max', name='hidden1', kernel_stride...=False, name='hidden3', units=64>, <sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>],\n",
      "      learning_momentum=0.9, learning_rate=0.002, learning_rule='momentum',\n",
      "      loss_type=None, n_iter=160, n_stable=10, normalize=None,\n",
      "      output=<sknn.nn.Layer `Softmax`: frozen=False, name='output', units=10>,\n",
      "      parameters=None, random_state=None, regularize=None,\n",
      "      valid_set=(array([[[[ 0.65882,  0.50196, ...,  0.6549 ,  0.6549 ],\n",
      "         [ 0.68235,  0.58431, ...,  0.6549 ,  0.68235],\n",
      "         ...,\n",
      "         [ 0.52157,  0.49412, ...,  0.7098 ,  0.73725],\n",
      "         [ 0.5098 ,  0.4902 , ...,  0.56078,  0.58039]],\n",
      "\n",
      "        [[ 0.79216,  0.67843, ...,  0.85098,  0....],\n",
      "       ...,\n",
      "       [ 0.,  0., ...,  0.,  0.],\n",
      "       [ 0.,  1., ...,  0.,  0.]], dtype=float32)),\n",
      "      valid_size=0.1, verbose=1, warning=None, weight_decay=None):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.66      0.61      1000\n",
      "          1       0.61      0.64      0.63      1000\n",
      "          2       0.43      0.45      0.44      1000\n",
      "          3       0.41      0.29      0.34      1000\n",
      "          4       0.52      0.39      0.45      1000\n",
      "          5       0.44      0.51      0.47      1000\n",
      "          6       0.55      0.65      0.60      1000\n",
      "          7       0.55      0.64      0.59      1000\n",
      "          8       0.66      0.69      0.67      1000\n",
      "          9       0.64      0.48      0.55      1000\n",
      "\n",
      "avg / total       0.54      0.54      0.53     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[656  33  54  24  18  16  24  31 117  27]\n",
      " [ 55 643  15  25  10  17  24  40  65 106]\n",
      " [ 93  18 445  48  92 108  95  64  25  12]\n",
      " [ 35  32  97 287  57 257 109  64  32  30]\n",
      " [ 49  14 151  41 394  71 124 130  20   6]\n",
      " [ 16  13 108 122  37 511  74  84  26   9]\n",
      " [ 11  25  73  57  70  55 652  32  11  14]\n",
      " [ 36   9  45  46  58  94  35 639  10  28]\n",
      " [115  56  27  15   9  18   9  20 686  45]\n",
      " [ 85 206  19  28  11  18  29  64  55 485]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "expected = y_test\n",
    "predicted = dcnn.predict(x_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (\n",
    "    dcnn, classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.1313976919651032, 2.2170264436139),\n",
       " (2.0094905072450637, 2.063455394241545),\n",
       " (1.9303788787126541, 1.9626552727487352),\n",
       " (1.8674136102199554, 1.8866599853171242),\n",
       " (1.8192131865024566, 1.8302125535408655),\n",
       " (1.7739794939756393, 1.7859295705954235),\n",
       " (1.7408700364828109, 1.7501551089021894),\n",
       " (1.7288502168655395, 1.7187697880797916),\n",
       " (1.689844034910202, 1.6910531851318147),\n",
       " (1.669118698835373, 1.6659734668334325),\n",
       " (1.6496987628936768, 1.6441864508390427),\n",
       " (1.6293941867351531, 1.6242887194951374),\n",
       " (1.6168639010190964, 1.6057418637805514),\n",
       " (1.6217393636703492, 1.589626677731673),\n",
       " (1.578944970369339, 1.5741784630219142),\n",
       " (1.5730746364593506, 1.5598156701193915),\n",
       " (1.5589076536893844, 1.5486967722906007),\n",
       " (1.5480487024784089, 1.5361990015374289),\n",
       " (1.5463894748687743, 1.5241086859504382),\n",
       " (1.5303162789344789, 1.5143978528843987),\n",
       " (1.534213799238205, 1.506165826651785),\n",
       " (1.5103626608848573, 1.4976868675152462),\n",
       " (1.5051646214723586, 1.4884281394879024),\n",
       " (1.4970894515514375, 1.4820453462666936),\n",
       " (1.4902543693780899, 1.473823985921012),\n",
       " (1.4995882141590118, 1.467383122973972),\n",
       " (1.4865334665775298, 1.4602921571003067),\n",
       " (1.4791798928380013, 1.4541122178236643),\n",
       " (1.4909547567367554, 1.4477418903178638),\n",
       " (1.4853275337815284, 1.4422864572869407),\n",
       " (1.4688609850406646, 1.4383387276530266),\n",
       " (1.4877185148000718, 1.4332513213488791),\n",
       " (1.4548546630144119, 1.4274605918924015),\n",
       " (1.4438231033086777, 1.4210072161753973),\n",
       " (1.4557375335693359, 1.4173200651009878),\n",
       " (1.4335653036832809, 1.413003193007575),\n",
       " (1.4713535708189012, 1.4092301323678758),\n",
       " (1.4340970712900161, 1.4051457795500755),\n",
       " (1.4323450177907944, 1.3993645609749688),\n",
       " (1.429092089533806, 1.3955749226941003),\n",
       " (1.425189043879509, 1.3924324119091034),\n",
       " (1.4173231846094132, 1.3896673495239682),\n",
       " (1.4119729968905448, 1.3850817302862803),\n",
       " (1.418959059715271, 1.3809417722291417),\n",
       " (1.4236691534519195, 1.377906189262867),\n",
       " (1.4091265130043029, 1.3751879549026489),\n",
       " (1.4178098073601724, 1.370417726635933),\n",
       " (1.410787960588932, 1.3685508533318838),\n",
       " (1.3956016653776169, 1.366712908645471),\n",
       " (1.3949794676899909, 1.359628241194619),\n",
       " (1.3895147782564163, 1.3580070331361558),\n",
       " (1.3935738521814347, 1.3554947120613523),\n",
       " (1.3946883174777032, 1.3527990977300537),\n",
       " (1.3931080400943756, 1.3496175668968096),\n",
       " (1.3909424924850464, 1.3474376324481434),\n",
       " (1.3821284031867982, 1.3449091122547785),\n",
       " (1.3804277729988099, 1.3417441009812885),\n",
       " (1.3813625374436378, 1.3376463372508685),\n",
       " (1.3718511438369752, 1.336066583428118),\n",
       " (1.370235837996006, 1.3334184530708524),\n",
       " (1.3944213053584098, 1.332503967748748),\n",
       " (1.369133154451847, 1.3280194355050723),\n",
       " (1.3958667778968812, 1.3241718593570921),\n",
       " (1.3660986784100533, 1.3232010214527448),\n",
       " (1.3810655012726785, 1.3183020331131088),\n",
       " (1.3573814523220062, 1.3185539075401094),\n",
       " (1.3668341943621636, 1.31587194595072),\n",
       " (1.3657211187481879, 1.3120329619116253),\n",
       " (1.3679743117094041, 1.3119730443093511),\n",
       " (1.400451457798481, 1.3095744481351641),\n",
       " (1.3692652878165246, 1.3066642821497387),\n",
       " (1.3668990749120713, 1.3031772823466194),\n",
       " (1.3640218603610992, 1.3046317832006349),\n",
       " (1.3567967501282692, 1.3016910522182783),\n",
       " (1.3560677218437194, 1.2995201632049349),\n",
       " (1.3597207620739937, 1.2974637441502677),\n",
       " (1.3607363691926002, 1.2926932304104168),\n",
       " (1.3528807884454728, 1.2920509658257167),\n",
       " (1.3522732385993004, 1.2907261360022757),\n",
       " (1.3525042617321015, 1.2878484080235164),\n",
       " (1.3464963549375535, 1.2859699190987481),\n",
       " (1.335820803642273, 1.2851206331451734),\n",
       " (1.3307479044795036, 1.2817077571153641),\n",
       " (1.3375888955593109, 1.2784683695435524),\n",
       " (1.3393332266807556, 1.2792599326703284),\n",
       " (1.3598040261864661, 1.2786297909087605),\n",
       " (1.3443799018859863, 1.2758531888657145),\n",
       " (1.3413133138418198, 1.2741286207238833),\n",
       " (1.3484412053227424, 1.2723217009504637),\n",
       " (1.3572816613316536, 1.269796484510104),\n",
       " (1.3290043240785598, 1.2683491769764159),\n",
       " (1.3217535102367401, 1.265374132990837),\n",
       " (1.3232666328549385, 1.2644711506035593),\n",
       " (1.3533437943458557, 1.2620397609141139),\n",
       " (1.3248531782627107, 1.2633550498220656),\n",
       " (1.3352071365714073, 1.2597347526748974),\n",
       " (1.3156245070695878, 1.258124071194066),\n",
       " (1.3303056287765502, 1.2546631406744322),\n",
       " (1.3439248487353326, 1.2547218642963303),\n",
       " (1.3356469082832336, 1.2531961762573984),\n",
       " (1.3073635348677635, 1.2510998602377044),\n",
       " (1.3442316767573357, 1.2490216636326579),\n",
       " (1.3114475491642952, 1.249784308175246),\n",
       " (1.3534707358479501, 1.2469483725892172),\n",
       " (1.3369970917701721, 1.24845359146595),\n",
       " (1.3243622767925263, 1.244113624062803),\n",
       " (1.3136298382282257, 1.2430851022071308),\n",
       " (1.306255019903183, 1.2394758777154817),\n",
       " (1.3324167203903199, 1.2394526467720668),\n",
       " (1.3165444803237916, 1.2398544320795271),\n",
       " (1.3074435588717461, 1.2367254912190968),\n",
       " (1.3419541174173355, 1.2341380418340364),\n",
       " (1.3166752350330353, 1.2339090762204594),\n",
       " (1.3191367459297181, 1.2320227270656161),\n",
       " (1.3382278078794478, 1.2308901375863288),\n",
       " (1.3403291735053062, 1.2291116357843082),\n",
       " (1.3188450625538826, 1.2288745733102162),\n",
       " (1.3019700688123703, 1.2271723009811508),\n",
       " (1.3070760887861252, 1.2242479640245438),\n",
       " (1.2968461853265763, 1.2238571558064884),\n",
       " (1.3275686392188073, 1.2241336147983868),\n",
       " (1.3088308301568032, 1.2222084212634299),\n",
       " (1.2967635568976403, 1.2199531304836273),\n",
       " (1.3055172029137612, 1.2200375561581718),\n",
       " (1.3022102689743043, 1.2165142003032896),\n",
       " (1.3193667948246002, 1.2160823392868041),\n",
       " (1.3200089052319526, 1.2144590695699056),\n",
       " (1.3161814627051354, 1.2140577229526308),\n",
       " (1.3040010422468185, 1.2109551867180401),\n",
       " (1.3130447176098823, 1.2131099105543561),\n",
       " (1.3083703577518464, 1.2093332489000426),\n",
       " (1.2999455749988555, 1.2076111030247476),\n",
       " (1.3039108049869537, 1.2049156239959928)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected=np.reshape(expected,(10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [0],\n",
       "       [8],\n",
       "       ..., \n",
       "       [2],\n",
       "       [5],\n",
       "       [7]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 Cifar 10 images\n",
      "correct:  5398 wrong:  4602 error rate:  46.02 %\n",
      "got correctly  53.98 %\n"
     ]
    }
   ],
   "source": [
    "num=len(expected)\n",
    "r=0\n",
    "w=0\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(expected[i],predicted[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "print (\"tested \",  num, \"Cifar 10 images\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
