{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 920M (CNMeM is disabled, cuDNN not available)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os    \n",
    "#os.environ['THEANO_FLAGS'] = \"device=gpu1\"  \n",
    "#os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32,lib.cnmem=1\"\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "import theano\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import containers\n",
    "from keras.layers import Input, Dense\n",
    "#from keras.layers.core import AutoEncoder\n",
    "from keras.activations import sigmoid\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "\n",
    "nb_classes = 10\n",
    "nb_hidden_layers = [784, 676, 484, 324, 144, 64, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_test.shape, 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Layer-wise pretraining\n",
    "encoders = []\n",
    "X_train_tmp = np.copy(X_train)\n",
    "print(X_train_tmp.shape)\n",
    "nfold=10\n",
    "nb_epoch=50\n",
    "batch_size=256\n",
    "random_state =6567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the layer 1: Input 784 -> Output 676\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s - loss: 0.3089     \n",
      "(60000, 676)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>]\n",
      "Training the layer 2: Input 676 -> Output 484\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 4s - loss: 0.5381     \n",
      "(60000, 484)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>]\n",
      "Training the layer 3: Input 484 -> Output 324\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2s - loss: 0.5389     \n",
      "(60000, 324)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>, <keras.engine.training.Model object at 0x7fa6a7622710>]\n",
      "Training the layer 4: Input 324 -> Output 144\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 1s - loss: 0.6663     \n",
      "(60000, 144)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>, <keras.engine.training.Model object at 0x7fa6a7622710>, <keras.engine.training.Model object at 0x7fa6aea8b320>]\n",
      "Training the layer 5: Input 144 -> Output 64\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s - loss: 1.0667     \n",
      "(60000, 64)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>, <keras.engine.training.Model object at 0x7fa6a7622710>, <keras.engine.training.Model object at 0x7fa6aea8b320>, <keras.engine.training.Model object at 0x7fa6a76d1518>]\n",
      "Training the layer 6: Input 64 -> Output 35\n",
      "compiling...\n",
      "fiting.pretraining for just few epochs..\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 0s - loss: 0.8299     \n",
      "(60000, 35)\n",
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>, <keras.engine.training.Model object at 0x7fa6a7622710>, <keras.engine.training.Model object at 0x7fa6aea8b320>, <keras.engine.training.Model object at 0x7fa6a76d1518>, <keras.engine.training.Model object at 0x7fa6a76bba20>]\n"
     ]
    }
   ],
   "source": [
    "for i, (n_in, n_out) in enumerate(zip(nb_hidden_layers[:-1], nb_hidden_layers[1:]), start=1):\n",
    "    print('Training the layer {}: Input {} -> Output {}'.format(i, n_in, n_out))\n",
    "    \n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(n_in,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(n_out, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(n_in, activation='relu')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    # we will not need a model to reconstruct\n",
    "    autoencoder = Model(input=input_img, output=decoded)\n",
    "    \n",
    "    # this model maps an input to its encoded representation\n",
    "    # this is the important model for encoding and need to be stacked\n",
    "    encoder = Model(input=input_img, output=encoded)\n",
    "\n",
    "    # create a placeholder for an encoded  input\n",
    "    encoded_input = Input(shape=(n_out,))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    # create the decoder model\n",
    "    decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
    "\n",
    "    print('compiling...')\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    print('fiting.pretraining for just few epochs..')\n",
    "    \n",
    "    autoencoder.fit(X_train_tmp, X_train_tmp,\n",
    "                nb_epoch=1,\n",
    "                batch_size=256,\n",
    "                shuffle=True)\n",
    "    \n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    #encoded_imgs = encoder.predict(X_train_tmp)\n",
    "    #decoded_imgs = decoder.predict(encoded_imgs)\n",
    "    \n",
    "    #SDAE needs new set of training examples with encoded rep for the next stack\n",
    "    X_train_tmp = encoder.predict(X_train_tmp)\n",
    "    print(X_train_tmp.shape)\n",
    "    \n",
    "    encoders.append(encoder)\n",
    "    print(encoders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.training.Model object at 0x7fa6af602748>, <keras.engine.training.Model object at 0x7fa6abdbe7b8>, <keras.engine.training.Model object at 0x7fa6a7622710>, <keras.engine.training.Model object at 0x7fa6aea8b320>, <keras.engine.training.Model object at 0x7fa6a76d1518>, <keras.engine.training.Model object at 0x7fa6a76bba20>]\n"
     ]
    }
   ],
   "source": [
    "print(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7fa6af72dcf8>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6e86bdbe0>\n",
      "2\n",
      "<keras.engine.topology.InputLayer object at 0x7fa6adf08da0>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6abe29550>\n",
      "2\n",
      "<keras.engine.topology.InputLayer object at 0x7fa6a7610ef0>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6a766a128>\n",
      "2\n",
      "<keras.engine.topology.InputLayer object at 0x7fa6aea6f630>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6aea6f828>\n",
      "2\n",
      "<keras.engine.topology.InputLayer object at 0x7fa6a76b0668>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6a76b02e8>\n",
      "2\n",
      "<keras.engine.topology.InputLayer object at 0x7fa6a76cf2e8>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6a76cf4a8>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for encoder in encoders:\n",
    "    #model.add(encoder)\n",
    "    #x=model.get_weights()\n",
    "    print(encoder.layers[0])\n",
    "\n",
    "    #print(encoder.layers[0].get_config())\n",
    "    print(len(encoder.layers[0].get_weights()))\n",
    "    \n",
    "    print(encoder.layers[1])\n",
    "\n",
    "    #print(encoder.layers[1].get_config())\n",
    "    print(len(encoder.layers[1].get_weights()))\n",
    "\n",
    "\n",
    "    ##print(encoder.layers[2]) ---> List Index out of range\n",
    "    #top_model.layer[2].set_weights(encoder.layers[0].get_weights())\n",
    "#model.summary()\n",
    "#print(type(x))\n",
    "#print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "784\n",
      "676\n",
      "484\n",
      "35\n",
      "324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (len(nb_hidden_layers))\n",
    "print (nb_hidden_layers[0])\n",
    "print (nb_hidden_layers[1])\n",
    "print (nb_hidden_layers[2])\n",
    "\n",
    "print (nb_hidden_layers[-1])\n",
    "print (nb_hidden_layers[3])\n",
    "\n",
    "##print (nb_hidden_layers[4])---> List out of range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is  0\n",
      "i is  1\n",
      "i is  2\n",
      "i is  3\n",
      "i is  4\n"
     ]
    }
   ],
   "source": [
    "# Build the top model to Dimension reduction\n",
    "input_img = Input(shape=(nb_hidden_layers[0],))\n",
    "top_encoded = Dense(nb_hidden_layers[1], activation='relu')(input_img)\n",
    "for i in range(len(nb_hidden_layers) - 2) :\n",
    "\n",
    "    top_encoded = Dense(nb_hidden_layers[i+2], activation='relu')(top_encoded)\n",
    "    print('i is ',i)\n",
    "     \n",
    "#top_encoded = Dense(nb_hidden_layers[3], activation='sigmoid')(top_encoded)\n",
    "\n",
    "# add the below line classify\n",
    "top_decoded = Dense(nb_hidden_layers[0], activation='sigmoid')(top_encoded)\n",
    "top_autoencoder = Model(input=input_img, output=top_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "top_encoder_only = Model(input=input_img, output=top_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7fa6af72db70>\n",
      "0\n",
      "<keras.layers.core.Dense object at 0x7fa6af72db38>\n",
      "2\n",
      "<keras.layers.core.Dense object at 0x7fa6a75bb7f0>\n",
      "2\n",
      "<keras.layers.core.Dense object at 0x7fa6abd6a7f0>\n",
      "2\n",
      "<keras.layers.core.Dense object at 0x7fa6a764fda0>\n",
      "2\n",
      "<keras.layers.core.Dense object at 0x7fa6abd7dbe0>\n",
      "2\n",
      "<keras.engine.training.Model object at 0x7fa6e86bdf98>\n"
     ]
    }
   ],
   "source": [
    "print(top_autoencoder.layers[0])\n",
    "print(len(top_autoencoder.layers[0].get_weights()))\n",
    "\n",
    "print(top_autoencoder.layers[1])\n",
    "print(len(top_autoencoder.layers[1].get_weights()))\n",
    "\n",
    "print(top_autoencoder.layers[2])\n",
    "print(len(top_autoencoder.layers[2].get_weights()))\n",
    "\n",
    "print(top_autoencoder.layers[3])\n",
    "print(len(top_autoencoder.layers[3].get_weights()))\n",
    "\n",
    "print(top_autoencoder.layers[4])\n",
    "print(len(top_autoencoder.layers[4].get_weights()))\n",
    "\n",
    "###index out of range\n",
    "print(top_autoencoder.layers[6])\n",
    "print(len(top_autoencoder.layers[6].get_weights()))\n",
    "\n",
    "print(top_encoder_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is  1\n",
      "2\n",
      "2\n",
      "i is  2\n",
      "2\n",
      "2\n",
      "i is  3\n",
      "2\n",
      "2\n",
      "i is  4\n",
      "2\n",
      "2\n",
      "i is  5\n",
      "2\n",
      "2\n",
      "i is  6\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for encoder in encoders:\n",
    "    print('i is ',i)\n",
    "    # stack the first models encoded layer and set weights\n",
    "    print(len(encoder.layers[1].get_weights()))\n",
    "    top_autoencoder.layers[i].set_weights(encoder.layers[1].get_weights())\n",
    "    print(len(top_autoencoder.layers[i].get_weights()))\n",
    "    i+=1\n",
    "    #if i == len(nb_hidden_layers)+1:\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "s_train, s_valid = train_test_split(X_train, test_size=0.3)\n",
    "v_train, v_valid = train_test_split(Y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7fa6abd7e470>\n",
      "Test score before fine turning: 692.301820703\n",
      "Test accuracy before fine turning: 0.0008\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 5s - loss: 587.9797 - acc: 0.0027 - val_loss: 558.0108 - val_acc: 0.0021\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 5s - loss: 549.0256 - acc: 0.0017 - val_loss: 542.2636 - val_acc: 0.0012\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 5s - loss: 539.6647 - acc: 0.0016 - val_loss: 539.3575 - val_acc: 0.0011\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 5s - loss: 534.6969 - acc: 0.0015 - val_loss: 531.7510 - val_acc: 8.8889e-04\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 5s - loss: 531.4921 - acc: 0.0015 - val_loss: 529.8543 - val_acc: 0.0015\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 5s - loss: 529.2668 - acc: 0.0015 - val_loss: 528.3006 - val_acc: 1.0000e-03\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 5s - loss: 527.8038 - acc: 0.0014 - val_loss: 526.8952 - val_acc: 0.0013\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 5s - loss: 526.7493 - acc: 0.0015 - val_loss: 525.5779 - val_acc: 0.0012\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 5s - loss: 525.8045 - acc: 0.0016 - val_loss: 524.9133 - val_acc: 0.0012\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 5s - loss: 524.9683 - acc: 0.0016 - val_loss: 525.5699 - val_acc: 0.0014\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 5s - loss: 523.5078 - acc: 0.0018 - val_loss: 521.9014 - val_acc: 0.0019\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 5s - loss: 521.9470 - acc: 0.0043 - val_loss: 520.9884 - val_acc: 0.0047\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 5s - loss: 520.9847 - acc: 0.0053 - val_loss: 520.2259 - val_acc: 0.0063\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 5s - loss: 519.8375 - acc: 0.0070 - val_loss: 519.0253 - val_acc: 0.0088\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 5s - loss: 518.6879 - acc: 0.0092 - val_loss: 518.1400 - val_acc: 0.0111\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 5s - loss: 518.0823 - acc: 0.0091 - val_loss: 517.3776 - val_acc: 0.0106\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 5s - loss: 517.6961 - acc: 0.0097 - val_loss: 516.8026 - val_acc: 0.0105\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 5s - loss: 517.3094 - acc: 0.0102 - val_loss: 517.5753 - val_acc: 0.0093\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 5s - loss: 517.0573 - acc: 0.0091 - val_loss: 516.4269 - val_acc: 0.0097\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 5s - loss: 516.6795 - acc: 0.0098 - val_loss: 517.0809 - val_acc: 0.0097\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 5s - loss: 516.4518 - acc: 0.0106 - val_loss: 516.3208 - val_acc: 0.0094\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 5s - loss: 516.2078 - acc: 0.0112 - val_loss: 515.8226 - val_acc: 0.0103\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 5s - loss: 515.8958 - acc: 0.0108 - val_loss: 516.3682 - val_acc: 0.0087\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 5s - loss: 515.5315 - acc: 0.0107 - val_loss: 515.5556 - val_acc: 0.0100\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 5s - loss: 515.2998 - acc: 0.0112 - val_loss: 515.3941 - val_acc: 0.0098\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 5s - loss: 515.0692 - acc: 0.0113 - val_loss: 515.3113 - val_acc: 0.0098\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.8830 - acc: 0.0116 - val_loss: 514.4924 - val_acc: 0.0099\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.6779 - acc: 0.0117 - val_loss: 514.3459 - val_acc: 0.0097\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.4418 - acc: 0.0120 - val_loss: 514.1811 - val_acc: 0.0100\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.3929 - acc: 0.0120 - val_loss: 514.7181 - val_acc: 0.0104\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.1539 - acc: 0.0120 - val_loss: 513.9934 - val_acc: 0.0134\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 5s - loss: 514.0778 - acc: 0.0127 - val_loss: 513.8534 - val_acc: 0.0102\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.8274 - acc: 0.0115 - val_loss: 513.7283 - val_acc: 0.0106\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.7337 - acc: 0.0119 - val_loss: 513.1852 - val_acc: 0.0100\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.4937 - acc: 0.0119 - val_loss: 514.1612 - val_acc: 0.0130\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.5011 - acc: 0.0127 - val_loss: 513.9731 - val_acc: 0.0118\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.2420 - acc: 0.0120 - val_loss: 513.7485 - val_acc: 0.0125\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.2767 - acc: 0.0119 - val_loss: 513.6997 - val_acc: 0.0131\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 5s - loss: 513.1276 - acc: 0.0125 - val_loss: 513.1159 - val_acc: 0.0114\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.9105 - acc: 0.0123 - val_loss: 512.6748 - val_acc: 0.0132\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.8359 - acc: 0.0122 - val_loss: 512.8481 - val_acc: 0.0139\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.8330 - acc: 0.0134 - val_loss: 512.8614 - val_acc: 0.0132\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.6982 - acc: 0.0129 - val_loss: 512.6413 - val_acc: 0.0118\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.5616 - acc: 0.0133 - val_loss: 512.6018 - val_acc: 0.0111\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.4530 - acc: 0.0132 - val_loss: 512.2932 - val_acc: 0.0121\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.4978 - acc: 0.0130 - val_loss: 512.1804 - val_acc: 0.0124\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.3328 - acc: 0.0126 - val_loss: 512.3501 - val_acc: 0.0131\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.1831 - acc: 0.0128 - val_loss: 513.2361 - val_acc: 0.0142\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.2046 - acc: 0.0126 - val_loss: 511.8959 - val_acc: 0.0124\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 5s - loss: 512.1244 - acc: 0.0139 - val_loss: 511.8504 - val_acc: 0.0119\n",
      "Test score after fine turning: 520.590193359\n",
      "Test accuracy after fine turning: 0.0108\n"
     ]
    }
   ],
   "source": [
    "print(top_autoencoder)\n",
    "\n",
    "top_autoencoder.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "score = top_autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "print('Test score before fine turning:', score[0])\n",
    "print('Test accuracy before fine turning:', score[1])\n",
    "top_autoencoder.fit(s_train, s_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    validation_data=(s_valid, s_valid))\n",
    "score = top_autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "print('Test score after fine turning:', score[0])\n",
    "print('Test accuracy after fine turning:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59904/60000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "train_encoded_imgs = top_encoder_only.predict(X_train,batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 35)\n"
     ]
    }
   ],
   "source": [
    "print(train_encoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_encoded_imgs = top_encoder_only.predict(X_test,batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 35)\n"
     ]
    }
   ],
   "source": [
    "print(test_encoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf = clf.fit(train_encoded_imgs, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested  10000 digits\n",
      "correct:  9476 wrong:  524 error rate:  5.24 %\n",
      "got correctly  94.76 %\n",
      "524\n"
     ]
    }
   ],
   "source": [
    "num=len(test_encoded_imgs)\n",
    "r=0\n",
    "w=0\n",
    "wrngclassidx=[]\n",
    "#y_test = np.ravel(y_test)\n",
    "for i in range(num):\n",
    "        #print ('y_pred ',y_pred[i])\n",
    "        #print ('labels ',labels[i])\n",
    "        #without the use of all() returns error truth value of an array with more than one element is ambiguous\n",
    "        #if y_pred[i].all() == labels[i].all():\n",
    "        if np.array_equal(y_pred[i],Y_test[i]):\n",
    "            r+=1\n",
    "        else:\n",
    "            w+=1\n",
    "            wrngclassidx.append(i)\n",
    "print (\"tested \",  num, \"digits\")\n",
    "print (\"correct: \", r, \"wrong: \", w, \"error rate: \", float(w)*100/(r+w), \"%\")\n",
    "print (\"got correctly \", float(r)*100/(r+w), \"%\")\n",
    "print (len(wrngclassidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Testing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s - loss: 567.4929 - acc: 0.0062     \n",
      "<keras.layers.core.Dense object at 0x7f4a6deb0898>\n",
      "<built-in method append of list object at 0x7f4a769c60c8>\n",
      "(60000, 784)\n",
      "[[  2.08194950e-04   1.61045158e-04   1.91865693e-04 ...,   4.11617657e-04\n",
      "    2.06225828e-04   2.25820302e-04]\n",
      " [  8.34012681e-05   1.15721450e-04   6.54617252e-05 ...,   1.00052559e-04\n",
      "    1.18069322e-04   1.19686571e-04]\n",
      " [  1.55348040e-03   2.11423798e-03   2.02637399e-03 ...,   1.87618355e-03\n",
      "    1.72902329e-03   1.79942453e-03]\n",
      " ..., \n",
      " [  2.50088226e-04   3.11022683e-04   2.65567418e-04 ...,   5.46693511e-04\n",
      "    3.07242037e-04   3.17488448e-04]\n",
      " [  1.88292644e-04   2.04064956e-04   9.50054527e-05 ...,   2.04343232e-04\n",
      "    2.87173170e-04   2.82932306e-04]\n",
      " [  3.08272341e-04   3.46488523e-04   2.56666623e-04 ...,   5.05295815e-04\n",
      "    2.51874444e-04   3.89833644e-04]]\n"
     ]
    }
   ],
   "source": [
    "input_img1 = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded1 = Dense(600, activation='sigmoid')(input_img1) #26X26\n",
    "decoded1 = Dense(784, activation='sigmoid')(encoded1)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "autoencoder1.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "autoencoder1.fit(X_train_tmp, X_train_tmp,\n",
    "                nb_epoch=nb_epoch,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "                #validation_data=(s_valid_noisy, s_valid),\n",
    "                #callbacks=callbacks)\n",
    "print(autoencoder1.layers[-1])\n",
    "# Store trainined weight and update training data\n",
    "encoders.append(autoencoder1.layers[-1])\n",
    "print(encoders.append)\n",
    "X_train_tmp = autoencoder1.predict(X_train_tmp)\n",
    "print(X_train_tmp.shape)\n",
    "print(X_train_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
